{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91MsGMTna_P9"
   },
   "source": [
    "# CBU5201 mini-project submission\n",
    "\n",
    "\n",
    "## What is the problem?\n",
    "\n",
    "This year's mini-project considers the problem of predicting whether a narrated story is true or not. Specifically, you will build a machine learning model that takes as an input an audio recording of **3-5 minutes** of duration and predicts whether the story being narrated is **true or not**. \n",
    "\n",
    "\n",
    "## Which dataset will I use?\n",
    "\n",
    "A total of 100 samples consisting of a complete audio recording, a *Language* attribute and a *Story Type* attribute have been made available for you to build your machine learning model. The audio recordings can be downloaded from:\n",
    "\n",
    "https://github.com/CBU5201Datasets/Deception\n",
    "\n",
    "A CSV file recording the *Language* attribute and *Story Type* of each audio file can be downloaded from:\n",
    "\n",
    "https://github.com/CBU5201Datasets/Deception/blob/main/CBU0521DD_stories_attributes.csv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## What will I submit?\n",
    "\n",
    "Your submission will consist of **one single Jupyter notebook** that should include:\n",
    "\n",
    "*   **Text cells**, describing in your own words, rigorously and concisely your approach, each implemented step and the results that you obtain,\n",
    "*   **Code cells**, implementing each step,\n",
    "*   **Output cells**, i.e. the output from each code cell,\n",
    "\n",
    "Your notebook **should have the structure** outlined below. Please make sure that you **run all the cells** and that the **output cells are saved** before submission. \n",
    "\n",
    "Please save your notebook as:\n",
    "\n",
    "* CBU5201_miniproject.ipynb\n",
    "\n",
    "\n",
    "## How will my submission be evaluated?\n",
    "\n",
    "This submission is worth 16 marks. We will value:\n",
    "\n",
    "*   Conciseness in your writing.\n",
    "*   Correctness in your methodology.\n",
    "*   Correctness in your analysis and conclusions.\n",
    "*   Completeness.\n",
    "*   Originality and efforts to try something new.\n",
    "\n",
    "(4 marks are given based on your audio submission from stage 1.)\n",
    "\n",
    "**The final performance of your solutions will not influence your grade**. We will grade your understanding. If you have an good understanding, you will be using the right methodology, selecting the right approaches, assessing correctly the quality of your solutions, sometimes acknowledging that despite your attempts your solutions are not good enough, and critically reflecting on your work to suggest what you could have done differently. \n",
    "\n",
    "Note that **the problem that we are intending to solve is very difficult**. Do not despair if you do not get good results, **difficulty is precisely what makes it interesting** and **worth trying**. \n",
    "\n",
    "## Show the world what you can do \n",
    "\n",
    "Why don't you use **GitHub** to manage your project? GitHub can be used as a presentation card that showcases what you have done and gives evidence of your data science skills, knowledge and experience. **Potential employers are always looking for this kind of evidence**. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------- PLEASE USE THE STRUCTURE BELOW THIS LINE --------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B-FAUTT: The Boosting-led First-AUdio-Then-Text Approach for Deceptive Story Detection\n",
    "\n",
    "The full code will be made public on GitHub after the deadline at https://github.com/scris/ml-project-fautt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZaGn4ICrfqXZ"
   },
   "source": [
    "# 1 Author\n",
    "\n",
    "**Student Name**: Tianze Qiu\n",
    "\n",
    "**Student ID**: 221170249\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o38VQkcdKd6k"
   },
   "source": [
    "# 2 Problem formulation\n",
    "\n",
    "## 2.1 Problem\n",
    "\n",
    "We're given a dataset of audio recordings of stories, both in English and in Chinese, and their corresponding labels of deceptive or not. The task is to build a machine learning pipeline that can predict whether a story is deceptive or not based on the audio recording file.\n",
    "\n",
    "## 2.2 Why is it interesting?\n",
    "\n",
    "1. **Real-world application**: The ability to detect deceptive stories has a bunch of real-world applications, for example, in lie detection, fraud detection, fake news detection, etc.\n",
    "2. **Difficulty of the task**: The task is very challenging because it requires us to think of a way that can work fine in only 100 samples and gain reasonable accuracy.\n",
    "3. **Potential for creativity**: The task is open-ended and allows for a lot of creativity in the parts of feature engineering, model selection, and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPTSuaB9L2jU"
   },
   "source": [
    "# 3 Methodology\n",
    "\n",
    "Overall, we use a boosting-led approach utilizing cherry-picked first-audio-then-text multimodal features for this detection problem. These tasks below are involved during the procedure:\n",
    "\n",
    "## 3.1 Preparation\n",
    "\n",
    "First, we prepare the dataset. We derive a text version from the audio files, then translate and lemmatize it to build a text-based dataset. This dataset is used along the original audio-based one.\n",
    "\n",
    "## 3.2 Feature Engineering\n",
    "\n",
    "Audio features are very high-dimensional, and model will be overfitting if original features are given. Also, it will be helpful is model is also assisted with features extracted from text.\n",
    "\n",
    "These are features used during this process. Their details will be described thoroughly in later sections.\n",
    "\n",
    "### Audio Features\n",
    "\n",
    "- [Main] Filter bank features extracted from audio waveform.\n",
    "- Basic voice characteristics, like energy, zero crossings, kurtosis and skew.\n",
    "- Silence related features, like silence count, duration, and joint features with things like language.\n",
    "\n",
    "### Text Features\n",
    "\n",
    "- [Main] TF-IDF features from lemmatized English text.\n",
    "- Basic linguistic features, like word count, sentence count, stop words, etc.\n",
    "- Other features like word richness and repetition ratio.\n",
    "\n",
    "After manually picking these features, we use a CatBoost model to distinguish the importance of all features. Some least important features are then removed to improve efficiency and eliminate overfitting possibilities.\n",
    "\n",
    "## 3.3 Train Process\n",
    "\n",
    "With these features extracted from both modalities, we do binary classification task to detect deceptive stories (label=1) vs truthful stories (label=0).\n",
    "\n",
    "The 100-sample dataset is split into 76 training and 24 test samples (76/24 split) for best performance. Stratified split is used to maintain class distribution, and Scikit-learn standard scaler is utilized to keep every feature in a uniform scale.\n",
    "\n",
    "Three different models are used:\n",
    "\n",
    "- CatBoost: A gradient boosting algorithm optimized for categorical features, known for its high efficiency and performance with minimal hyperparameter tuning.\n",
    "- Naive Bayes: A probabilistic classifier based on Bayes' theorem, commonly used for its simplicity and effectiveness in text classification tasks, especially when feature independence is assumed.\n",
    "- K-Nearest Neighbors (KNN): A non-parametric method that classifies samples based on the majority vote of the closest neighbors, with distance as the key metric for classification.\n",
    "\n",
    "They're stacked as one classifier with a final logistic regression estimator. And this classifier is fitted with the features and labels of the training subset.\n",
    "\n",
    "## 3.4 Validation Process\n",
    "\n",
    "We evaluate the performance of the model by these metrics:\n",
    "\n",
    "- Accuracy: This measures the proportion of correct predictions (both true positives and true negatives) out of all predictions made. It is a general indicator of the model's effectiveness.\n",
    "- ROC-AUC Score: The Receiver Operating Characteristic Area Under the Curve (ROC-AUC) score assesses the trade-off between true positive rate and false positive rate across different classification thresholds. A higher score indicates better model performance.\n",
    "- Classification Report: This includes precision, recall, F1-score, and support for each class:\n",
    "    - Precision: The proportion of positive predictions that are actually correct. High precision means that when the model predicts a class, it is likely correct.\n",
    "    - Recall: The proportion of actual positives that are correctly identified by the model. High recall means the model successfully identifies most positive instances.\n",
    "    - F1-Score: The harmonic mean of precision and recall, providing a balanced measure when there is an uneven class distribution.\n",
    "    - Support: The number of actual occurrences of each class in the dataset.\n",
    "- Confusion Matrix: A table showing the number of true positives, true negatives, false positives, and false negatives. This helps visualize the types of classification errors made by the model.\n",
    "\n",
    "Accuracy and ROC-AUC Score is the two main metrics used in measurement and comparison in the procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3BwrtEdLDit"
   },
   "source": [
    "# 4 Implemented ML prediction pipelines\n",
    "\n",
    "Describe the ML prediction pipelines that you will explore. Clearly identify their input and output, stages and format of the intermediate data structures moving from one stage to the next. It's up to you to decide which stages to include in your pipeline. After providing an overview, describe in more detail each one of the stages that you have included in their corresponding subsections (i.e. 4.1 Transformation stage, 4.2 Model stage, 4.3 Ensemble stage)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1nDXnzYLLH6"
   },
   "source": [
    "## 4.1 Transformation stage\n",
    "\n",
    "Describe any transformations, such as feature extraction. Identify input and output. Explain why you have chosen this transformation stage.\n",
    "\n",
    "First, we obtain a text-based side dataset from the original audio-based dataset for text features. The text-based dataset goes with three variants: ordinary, all-English and lemmatized all-English. The detailed way to obtain it will be talked about in the dataset section."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T13:26:36.305634Z",
     "start_time": "2024-12-29T13:26:35.108894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import codecs\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "cn_stopwords = set([ line.rstrip() for line in codecs.open('dataset/cn_stop_words.txt',\"r\", encoding=\"utf-8\")])\n",
    "en_stopwords = set([ line.rstrip() for line in codecs.open('dataset/en_stop_words.txt',\"r\", encoding=\"utf-8\")])\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def remove_new_line(text):\n",
    "    text = text.replace('\\n', '')\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "def lemmatize(review):\n",
    "    review = re.sub(r'[^a-zA-Z\\s]', '', review)\n",
    "    review = review.lower()\n",
    "    review = nltk.word_tokenize(review)\n",
    "    corpus = []\n",
    "    for y in review:\n",
    "        if y not in en_stopwords:\n",
    "            corpus.append(lemmatizer.lemmatize(y))\n",
    "    return ' '.join(corpus)\n",
    "\n",
    "# Retrieve three dataframes\n",
    "df_attributes = pd.read_csv('dataset/stories_attributes.csv')\n",
    "df_text = pd.read_csv('dataset/stories_in_text.csv')\n",
    "df_translated = pd.read_csv('dataset/stories_translated.csv')\n",
    "\n",
    "df = pd.merge(df_attributes, df_text, on=['filename', 'Language'])\n",
    "df = pd.merge(df, df_translated, on=['filename', 'Language'])\n",
    "\n",
    "# 0 = truth, 1 = deceptive\n",
    "df['label'] = np.where(df['Story_type'] == 'Deceptive Story', 1, 0)\n",
    "df['idx'] = range(len(df))\n",
    "df['text_line'] = df['text'].apply(remove_new_line)\n",
    "df['text_lemma'] = df['text_english'].apply(lemmatize)\n",
    "df = df.drop(columns=['Story_type'])\n",
    "df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     filename Language                                               text  \\\n",
       "0   00001.wav  Chinese  2021年的冬天，\\n我回了一趟老家探望外婆，\\n那年他身体不好，\\n住在离村子不远的小镇医...   \n",
       "1   00002.wav  Chinese  2022年暑假我终于实现了去云南旅行的梦想。\\n云南的美景和独特文化一直是我向往的，\\n而这...   \n",
       "2   00003.wav  Chinese  这是我的故事。\\n我的旅程从据著名的故宫开始，它是世界上最大保存\\n保存最完整的皇宫建筑群。...   \n",
       "3   00004.wav  Chinese  在2020年呢我报名参加了学校组织的美国研学活动，\\n我跟我的另外两个同学以及许多老师同学们...   \n",
       "4   00005.wav  Chinese  今天我想和大家分享我去年的陕西之旅，\\n当我踏上这片古老的土地，心中充满了期待与敬畏。\\n我...   \n",
       "..        ...      ...                                                ...   \n",
       "95  00096.wav  English   Uh. \\nW is a\\n uh my friends and I decided to...   \n",
       "96  00097.wav  Chinese  上周\\n我前往宜家\\n孤儿院\\n去看望我大学时期志愿服务时认识的小男孩，\\n浩浩，\\n那是一...   \n",
       "97  00098.wav  Chinese  呃上个周末我和我的朋友们准备去参加一场徒步旅行，\\n然后目标是一片森林，\\n那天的天气比较阴...   \n",
       "98  00099.wav  Chinese  啊一次有一次吧我和我的几个朋友去参加一个周末的艺术展览，\\n我们都挺喜欢艺术的，所以就提前计...   \n",
       "99  00100.wav  Chinese  2021年我去了一趟农村拜访我很久没见的表哥表哥一家住在偏远的乡下，那里风景优美，4周都是起...   \n",
       "\n",
       "                                         text_english  label  idx  \\\n",
       "0   In the winter of 2021, I went back to my homet...      0    0   \n",
       "1   I finally realized my dream of traveling to Yu...      0    1   \n",
       "2   This is my story. My journey begins with the f...      0    2   \n",
       "3   In 2020, I registered for the school's organiz...      0    3   \n",
       "4   Today, I would like to share with you my trip ...      0    4   \n",
       "..                                                ...    ...  ...   \n",
       "95  Uh. W is a uh my friends and I decided to go h...      0   95   \n",
       "96  Last week, I went to IKEA Orphanage to visit t...      1   96   \n",
       "97  Last weekend, my friends and I were planning t...      0   97   \n",
       "98  Ah, once in a while, my friends and I went to ...      1   98   \n",
       "99  In 2021, I went to the countryside to visit my...      0   99   \n",
       "\n",
       "                                            text_line  \\\n",
       "0   2021年的冬天，我回了一趟老家探望外婆，那年他身体不好，住在离村子不远的小镇医院里，冬天的...   \n",
       "1   2022年暑假我终于实现了去云南旅行的梦想。云南的美景和独特文化一直是我向往的，而这次旅行让...   \n",
       "2   这是我的故事。我的旅程从据著名的故宫开始，它是世界上最大保存保存最完整的皇宫建筑群。当我踏入...   \n",
       "3   在2020年呢我报名参加了学校组织的美国研学活动，我跟我的另外两个同学以及许多老师同学们一起...   \n",
       "4   今天我想和大家分享我去年的陕西之旅，当我踏上这片古老的土地，心中充满了期待与敬畏。我在陕西之...   \n",
       "..                                                ...   \n",
       "95  Uh. W is a uh my friends and I decided to go h...   \n",
       "96  上周我前往宜家孤儿院去看望我大学时期志愿服务时认识的小男孩，浩浩，那是一个安静的冬日午后阳光...   \n",
       "97  呃上个周末我和我的朋友们准备去参加一场徒步旅行，然后目标是一片森林，那天的天气比较阴沉，并且...   \n",
       "98  啊一次有一次吧我和我的几个朋友去参加一个周末的艺术展览，我们都挺喜欢艺术的，所以就提前计划好...   \n",
       "99  2021年我去了一趟农村拜访我很久没见的表哥表哥一家住在偏远的乡下，那里风景优美，4周都是起...   \n",
       "\n",
       "                                           text_lemma  \n",
       "0   winter hometown visit grandmother good health ...  \n",
       "1   finally realized dream traveling yunnan summer...  \n",
       "2   story journey famous forbidden city largest pr...  \n",
       "3   registered school organized study tour united ...  \n",
       "4   today share trip shaanxi year stepped ancient ...  \n",
       "..                                                ...  \n",
       "95  uh uh friend decided hiking life true uh left ...  \n",
       "96  week ikea orphanage visit boy met college volu...  \n",
       "97  weekend friend planning participate hiking tri...  \n",
       "98  friend attend weekend art exhibition love art ...  \n",
       "99  countryside visit cousin family hadnt long tim...  \n",
       "\n",
       "[100 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>Language</th>\n",
       "      <th>text</th>\n",
       "      <th>text_english</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "      <th>text_line</th>\n",
       "      <th>text_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001.wav</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>2021年的冬天，\\n我回了一趟老家探望外婆，\\n那年他身体不好，\\n住在离村子不远的小镇医...</td>\n",
       "      <td>In the winter of 2021, I went back to my homet...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021年的冬天，我回了一趟老家探望外婆，那年他身体不好，住在离村子不远的小镇医院里，冬天的...</td>\n",
       "      <td>winter hometown visit grandmother good health ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002.wav</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>2022年暑假我终于实现了去云南旅行的梦想。\\n云南的美景和独特文化一直是我向往的，\\n而这...</td>\n",
       "      <td>I finally realized my dream of traveling to Yu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2022年暑假我终于实现了去云南旅行的梦想。云南的美景和独特文化一直是我向往的，而这次旅行让...</td>\n",
       "      <td>finally realized dream traveling yunnan summer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00003.wav</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>这是我的故事。\\n我的旅程从据著名的故宫开始，它是世界上最大保存\\n保存最完整的皇宫建筑群。...</td>\n",
       "      <td>This is my story. My journey begins with the f...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>这是我的故事。我的旅程从据著名的故宫开始，它是世界上最大保存保存最完整的皇宫建筑群。当我踏入...</td>\n",
       "      <td>story journey famous forbidden city largest pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00004.wav</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>在2020年呢我报名参加了学校组织的美国研学活动，\\n我跟我的另外两个同学以及许多老师同学们...</td>\n",
       "      <td>In 2020, I registered for the school's organiz...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>在2020年呢我报名参加了学校组织的美国研学活动，我跟我的另外两个同学以及许多老师同学们一起...</td>\n",
       "      <td>registered school organized study tour united ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00005.wav</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>今天我想和大家分享我去年的陕西之旅，\\n当我踏上这片古老的土地，心中充满了期待与敬畏。\\n我...</td>\n",
       "      <td>Today, I would like to share with you my trip ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>今天我想和大家分享我去年的陕西之旅，当我踏上这片古老的土地，心中充满了期待与敬畏。我在陕西之...</td>\n",
       "      <td>today share trip shaanxi year stepped ancient ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>00096.wav</td>\n",
       "      <td>English</td>\n",
       "      <td>Uh. \\nW is a\\n uh my friends and I decided to...</td>\n",
       "      <td>Uh. W is a uh my friends and I decided to go h...</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>Uh. W is a uh my friends and I decided to go h...</td>\n",
       "      <td>uh uh friend decided hiking life true uh left ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>00097.wav</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>上周\\n我前往宜家\\n孤儿院\\n去看望我大学时期志愿服务时认识的小男孩，\\n浩浩，\\n那是一...</td>\n",
       "      <td>Last week, I went to IKEA Orphanage to visit t...</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>上周我前往宜家孤儿院去看望我大学时期志愿服务时认识的小男孩，浩浩，那是一个安静的冬日午后阳光...</td>\n",
       "      <td>week ikea orphanage visit boy met college volu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>00098.wav</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>呃上个周末我和我的朋友们准备去参加一场徒步旅行，\\n然后目标是一片森林，\\n那天的天气比较阴...</td>\n",
       "      <td>Last weekend, my friends and I were planning t...</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>呃上个周末我和我的朋友们准备去参加一场徒步旅行，然后目标是一片森林，那天的天气比较阴沉，并且...</td>\n",
       "      <td>weekend friend planning participate hiking tri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>00099.wav</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>啊一次有一次吧我和我的几个朋友去参加一个周末的艺术展览，\\n我们都挺喜欢艺术的，所以就提前计...</td>\n",
       "      <td>Ah, once in a while, my friends and I went to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>啊一次有一次吧我和我的几个朋友去参加一个周末的艺术展览，我们都挺喜欢艺术的，所以就提前计划好...</td>\n",
       "      <td>friend attend weekend art exhibition love art ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>00100.wav</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>2021年我去了一趟农村拜访我很久没见的表哥表哥一家住在偏远的乡下，那里风景优美，4周都是起...</td>\n",
       "      <td>In 2021, I went to the countryside to visit my...</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>2021年我去了一趟农村拜访我很久没见的表哥表哥一家住在偏远的乡下，那里风景优美，4周都是起...</td>\n",
       "      <td>countryside visit cousin family hadnt long tim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Then, we start to do feature extraction from these two datasets."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T13:39:16.674159Z",
     "start_time": "2024-12-29T13:39:16.666095Z"
    }
   },
   "cell_type": "code",
   "source": "feats = {'is_cn': df['Language'] == 'Chinese'}",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4.1.1 Audio Features\n",
    "\n",
    "We load the audio files first. Torchaudio is used as the backend."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T13:41:06.315611Z",
     "start_time": "2024-12-29T13:40:57.927048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import torchaudio\n",
    "\n",
    "list_waveform = []\n",
    "list_sample_rate = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    wav_file = f'dataset/stories/{df.iloc[i][\"filename\"]}'\n",
    "    waveform, sample_rate = torchaudio.load(wav_file)\n",
    "    list_waveform.append(waveform)\n",
    "    list_sample_rate.append(sample_rate)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2c462e68a5764c128ae63251904bc1a6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### [1] Silence-related Features\n",
    "\n",
    "Silence of more than 800 microseconds may reflect that the person is thinking \"what's next\", indicating a tendency that he or she may be thinking about how to lie. So the original and normalized length and overall duration are used.\n",
    "\n",
    "Also, we notice that people might be pausing more when saying English than Chinese for Chinese students, so we also add two language-balanced features as shown in the code.\n",
    "\n",
    "The code implementing it might be a little bit long as no 3rd-party package is used, and can be skipped from reading."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T13:45:19.207202Z",
     "start_time": "2024-12-29T13:45:14.589213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get Silence Indices\n",
    "def get_silence_indices(wf_np, sr):\n",
    "    frame_length = 0.025\n",
    "    frame_shift = 0.010\n",
    "    frame_length_samples = int(frame_length * sr)\n",
    "    frame_shift_samples = int(frame_shift * sr)\n",
    "    num_frames = int((len(wf_np) - frame_length_samples) / frame_shift_samples) + 1\n",
    "    frames = np.stack([\n",
    "        wf_np[i * frame_shift_samples: i * frame_shift_samples + frame_length_samples]\n",
    "        for i in range(num_frames)\n",
    "    ])\n",
    "    frame_energy = np.sum(frames ** 2, axis=1)\n",
    "\n",
    "    energy_threshold = np.mean(frame_energy) * 0.5\n",
    "    speech_frames = frame_energy > energy_threshold\n",
    "\n",
    "    # Detect silence frames\n",
    "    min_silence_duration = 1\n",
    "    min_silence_frames = int(min_silence_duration / frame_shift)\n",
    "    silence_indices = []\n",
    "    current_silence = []\n",
    "\n",
    "    for i, is_speech in enumerate(speech_frames):\n",
    "        if not is_speech:\n",
    "            current_silence.append(i)\n",
    "        else:\n",
    "            if len(current_silence) >= min_silence_frames:\n",
    "                silence_start = current_silence[0] * frame_shift\n",
    "                silence_end = (current_silence[-1] + 1) * frame_shift\n",
    "                silence_indices.append((silence_start, silence_end))\n",
    "            current_silence = []\n",
    "\n",
    "    if len(current_silence) >= min_silence_frames:\n",
    "        silence_start = current_silence[0] * frame_shift\n",
    "        silence_end = (current_silence[-1] + 1) * frame_shift\n",
    "        silence_indices.append((silence_start, silence_end))\n",
    "    return silence_indices\n",
    "\n",
    "silence_feats = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    # Get Silence Indices\n",
    "    silence_indices = get_silence_indices(list_waveform[i][0].numpy(), list_sample_rate[i])\n",
    "    silence_feats.append([])\n",
    "\n",
    "    # Silence Features\n",
    "    silence_feats[i].append(len(silence_indices))\n",
    "    silence_feats[i].append(sum([end - start for start, end in silence_indices]))\n",
    "\n",
    "    # Silence Features (Length Balanced)\n",
    "    silence_feats[i].append(len(silence_indices) / len(list_waveform[i][0]))\n",
    "    silence_feats[i].append(sum([end - start for start, end in silence_indices]) / len(list_waveform[i][0]))\n",
    "\n",
    "    # Silence Features (Language Balanced)\n",
    "    # Means: If Chinese, do *2, as for students, Chinese is more fluent\n",
    "    silence_feats[i].append(len(silence_indices) * (2 if df.iloc[i]['Language'] == 'Chinese' else 1))\n",
    "    silence_feats[i].append(sum([end - start for start, end in silence_indices]) * (2 if df.iloc[i]['Language'] == 'Chinese' else 1))\n",
    "\n",
    "feats['silence_count'] = [x[0] for x in silence_feats]\n",
    "feats['silence_duration'] = [x[1] for x in silence_feats]\n",
    "feats['silence_count__length'] = [x[2] for x in silence_feats]\n",
    "feats['silence_duration__length'] = [x[3] for x in silence_feats]\n",
    "feats['silence_count__lang'] = [x[4] for x in silence_feats]\n",
    "feats['silence_duration__lang'] = [x[5] for x in silence_feats]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0686cf4f2ea4312a966e2f29c4a1de1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### [2] Basic Audio Features\n",
    "\n",
    "We then add basic audio features into the features set. These features are: voice energy, zero crossings count, kurtosis and skew. These audio features provide key insights into the signal's characteristics. Voice energy measures the signal's strength, zero crossings count indicates the frequency of waveform changes, kurtosis assesses the \"tailedness\" of the signal's distribution, and skew evaluates its asymmetry. Together, they offer a robust representation of audio signals."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T13:48:01.835193Z",
     "start_time": "2024-12-29T13:47:52.788225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy import stats\n",
    "\n",
    "more_audio_feats = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    wf_np = list_waveform[i][0].numpy()\n",
    "    energy = np.sum(np.square(wf_np))\n",
    "    zero_crossings = np.sum(np.diff(np.signbit(wf_np)))\n",
    "    kurtosis = stats.kurtosis(wf_np)\n",
    "    skew = stats.skew(wf_np)\n",
    "    more_audio_feats.append([energy, zero_crossings, kurtosis, skew])\n",
    "more_audio_feats = np.array(more_audio_feats)\n",
    "\n",
    "feats['voice_energy'] = more_audio_feats[:,0]\n",
    "feats['voice_zero_crossings'] = more_audio_feats[:,1]\n",
    "feats['voice_kurtosis'] = more_audio_feats[:,2]\n",
    "feats['voice_skew'] = more_audio_feats[:,3]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "31727233933347bb86fa3dffb3f1b97c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### [3] Filtered Bank Audio Features\n",
    "\n",
    "Filtered bank (F-Bank) audio features are key for speech and audio analysis. The process involves several steps:\n",
    "\n",
    "1. Pre-emphasis: Boosts higher frequencies to balance the spectrum.\n",
    "2. Framing: Divides the signal into overlapping frames for temporal analysis.\n",
    "3. Windowing: Applies a Hamming window to reduce spectral leakage.\n",
    "4. FFT: Converts each frame to the frequency domain, producing a power spectrum.\n",
    "5. Mel Filter Bank: Applies filters based on the Mel scale, capturing perceptually relevant frequencies.\n",
    "6. Log Mel Energies: Takes the logarithm of the Mel energies for a more human-like auditory representation.\n",
    "\n",
    "These features are widely used in speech recognition and audio classification tasks. The code implementing this might be a little bit long as no 3rd-party package is used, and can be skipped from reading.\n",
    "\n",
    "Mean, min, and max for each F-Bank feature is used."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T13:55:23.598673Z",
     "start_time": "2024-12-29T13:55:23.586300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "\n",
    "# Do Pre-Emphasis\n",
    "def pre_emphasis(signal, pre_emphasis_co_eff=0.97):\n",
    "    emphasized_signal = torch.cat((signal[:1], signal[1:] - pre_emphasis_co_eff * signal[:-1]))\n",
    "    return emphasized_signal\n",
    "\n",
    "# Do Padding and Framing\n",
    "def framing(signal, frame_size, frame_stride, sample_rate):\n",
    "    frame_length = frame_size * sample_rate\n",
    "    frame_step = frame_stride * sample_rate\n",
    "    signal_length = signal.shape[0]\n",
    "    frame_length = int(round(frame_length))\n",
    "    frame_step = int(round(frame_step))\n",
    "    num_frames = int(math.ceil(float(abs(signal_length - frame_length)) / frame_step)) + 1\n",
    "\n",
    "    pad_signal_length = num_frames * frame_step + frame_length\n",
    "    z = torch.zeros(pad_signal_length - signal_length)\n",
    "    pad_signal = torch.cat((signal, z))\n",
    "\n",
    "    frames = pad_signal[\n",
    "        torch.arange(0, frame_length).unsqueeze(0) +\n",
    "        torch.arange(0, num_frames * frame_step, frame_step).unsqueeze(1).long()\n",
    "    ]\n",
    "    return frames\n",
    "\n",
    "# Add Hamming Window\n",
    "def windowing(frames):\n",
    "    window = torch.hamming_window(frames.shape[1])\n",
    "    windowed_frames = frames * window\n",
    "    return windowed_frames\n",
    "\n",
    "# Do Fourier Transform\n",
    "def compute_fft(frames, NFFT):\n",
    "    complex_spectrum = torch.fft.rfft(frames, n=NFFT)\n",
    "    power_spectrum = (complex_spectrum.real ** 2 + complex_spectrum.imag ** 2)\n",
    "    return power_spectrum\n",
    "\n",
    "# Do Mel Filter Banks\n",
    "def mel_filter_bank(sample_rate, NFFT, n_filt, low_freq=0, high_freq=None):\n",
    "    if high_freq is None:\n",
    "        high_freq = sample_rate / 2\n",
    "\n",
    "    def hz_to_mel(hz):\n",
    "        return 2595 * torch.log10(1 + hz / 700)\n",
    "\n",
    "    def mel_to_hz(mel):\n",
    "        return 700 * (10**(mel / 2595) - 1)\n",
    "\n",
    "    mel_low = hz_to_mel(torch.tensor(low_freq))\n",
    "    mel_high = hz_to_mel(torch.tensor(high_freq))\n",
    "    mel_points = torch.linspace(mel_low, mel_high, n_filt + 2)\n",
    "    hz_points = mel_to_hz(mel_points)\n",
    "    bin = torch.floor((NFFT + 1) * hz_points / sample_rate).long()\n",
    "\n",
    "    mel_f_bank = torch.zeros(n_filt, NFFT // 2 + 1)\n",
    "    for m in range(1, n_filt + 1):\n",
    "        f_m_minus = bin[m -1]\n",
    "        f_m = bin[m]\n",
    "        f_m_plus = bin[m +1]\n",
    "\n",
    "        for k in range(f_m_minus, f_m):\n",
    "            mel_f_bank[m-1, k] = (k - bin[m-1]) / (bin[m] - bin[m-1] + 1e-8)\n",
    "        for k in range(f_m, f_m_plus):\n",
    "            mel_f_bank[m-1, k] = (bin[m +1] - k) / (bin[m +1] - bin[m] + 1e-8)\n",
    "    return mel_f_bank\n",
    "\n",
    "def apply_mel_filter(power_spectrum, mel_f_bank):\n",
    "    mel_energies = torch.matmul(power_spectrum, mel_f_bank.t())\n",
    "    mel_energies = torch.clamp(mel_energies, min=1e-10)\n",
    "    return mel_energies\n",
    "\n",
    "def get_f_bank_feats(wf, sample_rate=16000, pre_emphasis_co_eff=0.97,\n",
    "                     frame_size=0.025, frame_stride=0.01, NFFT=512, n_filt=40):\n",
    "    emphasized_wf = pre_emphasis(wf, pre_emphasis_co_eff)\n",
    "    frames = framing(emphasized_wf, frame_size, frame_stride, sample_rate)\n",
    "    windowed_frames = windowing(frames)\n",
    "    power_spectrum = compute_fft(windowed_frames, NFFT)\n",
    "    processed_f_bank = mel_filter_bank(sample_rate, NFFT, n_filt)\n",
    "    mel_energies = apply_mel_filter(power_spectrum, processed_f_bank)\n",
    "    log_mel_features = torch.log(mel_energies)\n",
    "    return log_mel_features"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T13:55:52.746402Z",
     "start_time": "2024-12-29T13:55:45.382927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "f_audio_feats = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    # Get F_Banks Results\n",
    "    f_banks = np.asarray(get_f_bank_feats(list_waveform[i][0], list_sample_rate[i]))\n",
    "\n",
    "    # Calculate F_Banks Statistics\n",
    "    f_means = np.mean(f_banks, axis=0)  # (40,)\n",
    "    f_all_max = np.max(f_banks, axis=0)  # (40,)\n",
    "    f_all_min = np.min(f_banks, axis=0)  # (40,)\n",
    "    f_stats = np.concatenate([\n",
    "        f_means, f_all_max, f_all_min\n",
    "    ])\n",
    "    f_audio_feats.append(f_stats)\n",
    "\n",
    "f_audio_feats = np.array(f_audio_feats)\n",
    "feat_names = []\n",
    "for stat in ['mean', 'max', 'min']:\n",
    "    for i in range(40):\n",
    "        feat_names.append(f'f_bank_{stat}_{i}')\n",
    "\n",
    "for i, name in enumerate(feat_names):\n",
    "    feats[name] = f_audio_feats[:, i]\n",
    "\n",
    "df_feats = pd.DataFrame(feats)\n",
    "df_feats"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6ece2d528a9a442ebe7663ba0a144cf6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "    is_cn  silence_count  silence_duration  silence_count__length  \\\n",
       "0    True             27             39.24           5.192174e-06   \n",
       "1    True              4              5.56           7.718780e-07   \n",
       "2    True              5             10.75           8.705226e-07   \n",
       "3    True             14             20.74           2.192609e-06   \n",
       "4    True             15             22.22           2.937279e-06   \n",
       "..    ...            ...               ...                    ...   \n",
       "95  False             11             17.93           2.065372e-06   \n",
       "96   True             31             41.70           4.289652e-06   \n",
       "97   True              9             13.16           1.718577e-06   \n",
       "98   True              8             11.35           1.496372e-06   \n",
       "99   True              0              0.00           0.000000e+00   \n",
       "\n",
       "    silence_duration__length  silence_count__lang  silence_duration__lang  \\\n",
       "0                   0.000008                   54                   78.48   \n",
       "1                   0.000001                    8                   11.12   \n",
       "2                   0.000002                   10                   21.50   \n",
       "3                   0.000003                   28                   41.48   \n",
       "4                   0.000004                   30                   44.44   \n",
       "..                       ...                  ...                     ...   \n",
       "95                  0.000003                   11                   17.93   \n",
       "96                  0.000006                   62                   83.40   \n",
       "97                  0.000003                   18                   26.32   \n",
       "98                  0.000002                   16                   22.70   \n",
       "99                  0.000000                    0                    0.00   \n",
       "\n",
       "     voice_energy  voice_zero_crossings  voice_kurtosis  ...  f_bank_min_30  \\\n",
       "0      240.086258              300478.0       10.802467  ...     -12.651694   \n",
       "1    25020.804688              283295.0        6.063213  ...     -13.569064   \n",
       "2    56735.906250              293135.0        7.146604  ...     -15.622457   \n",
       "3    19778.640625              371382.0        8.957318  ...     -15.036171   \n",
       "4      189.070831              258467.0        6.062391  ...     -12.155800   \n",
       "..            ...                   ...             ...  ...            ...   \n",
       "95    4605.399902              184847.0        8.572104  ...     -15.389595   \n",
       "96   61091.558594              370643.0       19.504339  ...     -15.648572   \n",
       "97    3646.611572              154271.0        8.979318  ...     -15.673203   \n",
       "98    2999.765137              149432.0        5.805043  ...     -15.446148   \n",
       "99  115065.726562              332951.0        4.994162  ...     -17.917732   \n",
       "\n",
       "    f_bank_min_31  f_bank_min_32  f_bank_min_33  f_bank_min_34  f_bank_min_35  \\\n",
       "0      -12.503399     -12.590755     -11.775176     -11.508147     -11.246720   \n",
       "1      -12.389540     -11.697145     -11.324645     -11.532026     -11.258627   \n",
       "2      -15.197051     -15.086365     -14.994941     -14.642530     -14.364624   \n",
       "3      -15.391803     -15.108377     -14.685904     -14.608970     -14.444119   \n",
       "4      -12.282447     -11.745874     -11.336093     -11.355878     -10.746713   \n",
       "..            ...            ...            ...            ...            ...   \n",
       "95     -15.429474     -15.200507     -14.604245     -14.403071     -14.429158   \n",
       "96     -15.457879     -15.118999     -14.789861     -14.596526     -14.431129   \n",
       "97     -15.451294     -14.987769     -14.702625     -14.606583     -14.037570   \n",
       "98     -15.240155     -15.006281     -14.849434     -14.776314     -14.143353   \n",
       "99     -17.735743     -17.652746     -17.269127     -16.943993     -16.708250   \n",
       "\n",
       "    f_bank_min_36  f_bank_min_37  f_bank_min_38  f_bank_min_39  \n",
       "0      -10.893195     -10.535343     -10.292615     -10.631175  \n",
       "1      -12.141105     -14.172897     -14.942272     -15.357892  \n",
       "2      -13.973715     -14.193736     -13.854203     -13.514560  \n",
       "3      -14.246261     -13.865327     -13.662978     -13.567836  \n",
       "4      -10.516589     -10.324493     -10.271720     -10.323216  \n",
       "..            ...            ...            ...            ...  \n",
       "95     -13.865187     -13.907432     -14.386015     -14.591955  \n",
       "96     -14.217156     -14.117102     -14.373189     -14.782300  \n",
       "97     -13.957192     -13.999018     -14.339170     -14.603734  \n",
       "98     -13.926983     -13.881326     -14.300455     -14.641323  \n",
       "99     -16.531713     -16.525991     -16.550686     -16.851931  \n",
       "\n",
       "[100 rows x 131 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_cn</th>\n",
       "      <th>silence_count</th>\n",
       "      <th>silence_duration</th>\n",
       "      <th>silence_count__length</th>\n",
       "      <th>silence_duration__length</th>\n",
       "      <th>silence_count__lang</th>\n",
       "      <th>silence_duration__lang</th>\n",
       "      <th>voice_energy</th>\n",
       "      <th>voice_zero_crossings</th>\n",
       "      <th>voice_kurtosis</th>\n",
       "      <th>...</th>\n",
       "      <th>f_bank_min_30</th>\n",
       "      <th>f_bank_min_31</th>\n",
       "      <th>f_bank_min_32</th>\n",
       "      <th>f_bank_min_33</th>\n",
       "      <th>f_bank_min_34</th>\n",
       "      <th>f_bank_min_35</th>\n",
       "      <th>f_bank_min_36</th>\n",
       "      <th>f_bank_min_37</th>\n",
       "      <th>f_bank_min_38</th>\n",
       "      <th>f_bank_min_39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "      <td>39.24</td>\n",
       "      <td>5.192174e-06</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>54</td>\n",
       "      <td>78.48</td>\n",
       "      <td>240.086258</td>\n",
       "      <td>300478.0</td>\n",
       "      <td>10.802467</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.651694</td>\n",
       "      <td>-12.503399</td>\n",
       "      <td>-12.590755</td>\n",
       "      <td>-11.775176</td>\n",
       "      <td>-11.508147</td>\n",
       "      <td>-11.246720</td>\n",
       "      <td>-10.893195</td>\n",
       "      <td>-10.535343</td>\n",
       "      <td>-10.292615</td>\n",
       "      <td>-10.631175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>5.56</td>\n",
       "      <td>7.718780e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>8</td>\n",
       "      <td>11.12</td>\n",
       "      <td>25020.804688</td>\n",
       "      <td>283295.0</td>\n",
       "      <td>6.063213</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.569064</td>\n",
       "      <td>-12.389540</td>\n",
       "      <td>-11.697145</td>\n",
       "      <td>-11.324645</td>\n",
       "      <td>-11.532026</td>\n",
       "      <td>-11.258627</td>\n",
       "      <td>-12.141105</td>\n",
       "      <td>-14.172897</td>\n",
       "      <td>-14.942272</td>\n",
       "      <td>-15.357892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>10.75</td>\n",
       "      <td>8.705226e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>10</td>\n",
       "      <td>21.50</td>\n",
       "      <td>56735.906250</td>\n",
       "      <td>293135.0</td>\n",
       "      <td>7.146604</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.622457</td>\n",
       "      <td>-15.197051</td>\n",
       "      <td>-15.086365</td>\n",
       "      <td>-14.994941</td>\n",
       "      <td>-14.642530</td>\n",
       "      <td>-14.364624</td>\n",
       "      <td>-13.973715</td>\n",
       "      <td>-14.193736</td>\n",
       "      <td>-13.854203</td>\n",
       "      <td>-13.514560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>20.74</td>\n",
       "      <td>2.192609e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>28</td>\n",
       "      <td>41.48</td>\n",
       "      <td>19778.640625</td>\n",
       "      <td>371382.0</td>\n",
       "      <td>8.957318</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.036171</td>\n",
       "      <td>-15.391803</td>\n",
       "      <td>-15.108377</td>\n",
       "      <td>-14.685904</td>\n",
       "      <td>-14.608970</td>\n",
       "      <td>-14.444119</td>\n",
       "      <td>-14.246261</td>\n",
       "      <td>-13.865327</td>\n",
       "      <td>-13.662978</td>\n",
       "      <td>-13.567836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "      <td>22.22</td>\n",
       "      <td>2.937279e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>30</td>\n",
       "      <td>44.44</td>\n",
       "      <td>189.070831</td>\n",
       "      <td>258467.0</td>\n",
       "      <td>6.062391</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.155800</td>\n",
       "      <td>-12.282447</td>\n",
       "      <td>-11.745874</td>\n",
       "      <td>-11.336093</td>\n",
       "      <td>-11.355878</td>\n",
       "      <td>-10.746713</td>\n",
       "      <td>-10.516589</td>\n",
       "      <td>-10.324493</td>\n",
       "      <td>-10.271720</td>\n",
       "      <td>-10.323216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>17.93</td>\n",
       "      <td>2.065372e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>11</td>\n",
       "      <td>17.93</td>\n",
       "      <td>4605.399902</td>\n",
       "      <td>184847.0</td>\n",
       "      <td>8.572104</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.389595</td>\n",
       "      <td>-15.429474</td>\n",
       "      <td>-15.200507</td>\n",
       "      <td>-14.604245</td>\n",
       "      <td>-14.403071</td>\n",
       "      <td>-14.429158</td>\n",
       "      <td>-13.865187</td>\n",
       "      <td>-13.907432</td>\n",
       "      <td>-14.386015</td>\n",
       "      <td>-14.591955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>True</td>\n",
       "      <td>31</td>\n",
       "      <td>41.70</td>\n",
       "      <td>4.289652e-06</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>62</td>\n",
       "      <td>83.40</td>\n",
       "      <td>61091.558594</td>\n",
       "      <td>370643.0</td>\n",
       "      <td>19.504339</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.648572</td>\n",
       "      <td>-15.457879</td>\n",
       "      <td>-15.118999</td>\n",
       "      <td>-14.789861</td>\n",
       "      <td>-14.596526</td>\n",
       "      <td>-14.431129</td>\n",
       "      <td>-14.217156</td>\n",
       "      <td>-14.117102</td>\n",
       "      <td>-14.373189</td>\n",
       "      <td>-14.782300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>13.16</td>\n",
       "      <td>1.718577e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>18</td>\n",
       "      <td>26.32</td>\n",
       "      <td>3646.611572</td>\n",
       "      <td>154271.0</td>\n",
       "      <td>8.979318</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.673203</td>\n",
       "      <td>-15.451294</td>\n",
       "      <td>-14.987769</td>\n",
       "      <td>-14.702625</td>\n",
       "      <td>-14.606583</td>\n",
       "      <td>-14.037570</td>\n",
       "      <td>-13.957192</td>\n",
       "      <td>-13.999018</td>\n",
       "      <td>-14.339170</td>\n",
       "      <td>-14.603734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>11.35</td>\n",
       "      <td>1.496372e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>16</td>\n",
       "      <td>22.70</td>\n",
       "      <td>2999.765137</td>\n",
       "      <td>149432.0</td>\n",
       "      <td>5.805043</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.446148</td>\n",
       "      <td>-15.240155</td>\n",
       "      <td>-15.006281</td>\n",
       "      <td>-14.849434</td>\n",
       "      <td>-14.776314</td>\n",
       "      <td>-14.143353</td>\n",
       "      <td>-13.926983</td>\n",
       "      <td>-13.881326</td>\n",
       "      <td>-14.300455</td>\n",
       "      <td>-14.641323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>115065.726562</td>\n",
       "      <td>332951.0</td>\n",
       "      <td>4.994162</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.917732</td>\n",
       "      <td>-17.735743</td>\n",
       "      <td>-17.652746</td>\n",
       "      <td>-17.269127</td>\n",
       "      <td>-16.943993</td>\n",
       "      <td>-16.708250</td>\n",
       "      <td>-16.531713</td>\n",
       "      <td>-16.525991</td>\n",
       "      <td>-16.550686</td>\n",
       "      <td>-16.851931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 131 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4.1.2 Text Features\n",
    "\n",
    "#### [1] Basic Linguistic Features\n",
    "\n",
    "We count for modal particles, new lines, sentences and stop words in English, and word count in the lemmatized English version. Also, we add features like repetition ratio, word richness and length in English."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T13:57:32.954369Z",
     "start_time": "2024-12-29T13:57:31.402166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def count_modal_particles(text):\n",
    "    particles = [\n",
    "        '啊', '呀', '啦', '吧', '呢', '嘛', '呗', '么', '噢', '呃', '额', '唔', '嗯',\n",
    "        ' uh ', 'uh,', '\\nuh ', 'uh.', ' oh ', 'oh,', '\\noh ', 'oh.', ' um ', 'um,', '\\num ', 'um.', ' ah ', 'ah,', '\\nah ', 'ah.',\n",
    "    ]\n",
    "    count = 0\n",
    "    for particle in particles:\n",
    "        count += len(re.findall(particle, text.lower()))\n",
    "    return count\n",
    "\n",
    "def count_new_line(text):\n",
    "    return len(re.findall('\\n', text))\n",
    "\n",
    "def calculate_repetition(text):\n",
    "    words = [w for w in text.split() if w]\n",
    "    if not words:\n",
    "        return 0\n",
    "\n",
    "    word_counts = {}\n",
    "    for word in words:\n",
    "        word_counts[word] = word_counts.get(word, 0) + 1\n",
    "    repeated_words = sum(count - 1 for count in word_counts.values())\n",
    "    repetition_ratio = repeated_words / len(words)\n",
    "\n",
    "    return repetition_ratio\n",
    "\n",
    "def count_stop_words(lang, text):\n",
    "    stopwords = cn_stopwords if lang == 'Chinese' else en_stopwords\n",
    "    count = 0\n",
    "    for word in stopwords:\n",
    "        pattern = r'\\b' + re.escape(word) + r'\\b'\n",
    "        try:\n",
    "            matches = re.findall(pattern, text.lower())\n",
    "            count += len(matches)\n",
    "        except re.error:\n",
    "            continue\n",
    "    return count\n",
    "\n",
    "feats['modal_particles'] = df['text'].apply(count_modal_particles)\n",
    "feats['new_line'] = df['text'].apply(count_new_line)\n",
    "feats['repetition'] = df['text_line'].apply(calculate_repetition)\n",
    "feats['stop_words'] = [\n",
    "    count_stop_words(row['Language'], row['text_line'])\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "feats['length_en'] = df['text_english'].apply(len)\n",
    "feats['word_count_lemma'] = df['text_lemma'].apply(lambda x: x.split()) \\\n",
    "    .apply(len).apply(lambda x: x + 1)\n",
    "feats['word_richness'] = df['text_english'].apply(lambda x: len(set(x)) / len(x))\n",
    "feats['sentence_count'] = df['text_english'].apply(\n",
    "    lambda x: x.count('.') + x.count('!') + x.count('?')\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### [2] TF-IDF NLP Features\n",
    "\n",
    "TF-IDF (Term Frequency-Inverse Document Frequency) is a numerical statistic used in information retrieval and text mining. It evaluates a word’s importance within a document by considering both its frequency in the document (TF) and its rarity across the entire corpus (IDF), helping identify significant terms.\n",
    "\n",
    "We use original 100 TF-IDF matrix features, their vector length, mean and standard deviation as the features to describe the story in pure numbers. The Scikit-learn implementation is used."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T13:57:37.029665Z",
     "start_time": "2024-12-29T13:57:36.958571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF Related Features\n",
    "tfidf_en = TfidfVectorizer(\n",
    "    max_features=100,\n",
    "    ngram_range=(1, 3),\n",
    "    stop_words='english'\n",
    ")\n",
    "tfidf_matrix_en = tfidf_en.fit_transform(df['text_lemma'])\n",
    "\n",
    "feats['tfidf_vec_len'] = pd.Series([len(x.indices) for x in tfidf_matrix_en])\n",
    "feats['tfidf_mean'] = pd.Series(np.array(tfidf_matrix_en.mean(axis=1)).flatten())\n",
    "feats['tfidf_std'] =  pd.Series([np.std(x.data) for x in tfidf_matrix_en])\n",
    "\n",
    "for i in range(100):\n",
    "    feats[f'tfidf_{i}'] = pd.Series(tfidf_matrix_en.toarray()[i])\n",
    "\n",
    "df_feats = pd.DataFrame(feats)\n",
    "df_feats"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    is_cn  silence_count  silence_duration  silence_count__length  \\\n",
       "0    True             27             39.24           5.192174e-06   \n",
       "1    True              4              5.56           7.718780e-07   \n",
       "2    True              5             10.75           8.705226e-07   \n",
       "3    True             14             20.74           2.192609e-06   \n",
       "4    True             15             22.22           2.937279e-06   \n",
       "..    ...            ...               ...                    ...   \n",
       "95  False             11             17.93           2.065372e-06   \n",
       "96   True             31             41.70           4.289652e-06   \n",
       "97   True              9             13.16           1.718577e-06   \n",
       "98   True              8             11.35           1.496372e-06   \n",
       "99   True              0              0.00           0.000000e+00   \n",
       "\n",
       "    silence_duration__length  silence_count__lang  silence_duration__lang  \\\n",
       "0                   0.000008                   54                   78.48   \n",
       "1                   0.000001                    8                   11.12   \n",
       "2                   0.000002                   10                   21.50   \n",
       "3                   0.000003                   28                   41.48   \n",
       "4                   0.000004                   30                   44.44   \n",
       "..                       ...                  ...                     ...   \n",
       "95                  0.000003                   11                   17.93   \n",
       "96                  0.000006                   62                   83.40   \n",
       "97                  0.000003                   18                   26.32   \n",
       "98                  0.000002                   16                   22.70   \n",
       "99                  0.000000                    0                    0.00   \n",
       "\n",
       "     voice_energy  voice_zero_crossings  voice_kurtosis  ...  tfidf_90  \\\n",
       "0      240.086258              300478.0       10.802467  ...       0.0   \n",
       "1    25020.804688              283295.0        6.063213  ...       0.0   \n",
       "2    56735.906250              293135.0        7.146604  ...       0.0   \n",
       "3    19778.640625              371382.0        8.957318  ...       0.0   \n",
       "4      189.070831              258467.0        6.062391  ...       0.0   \n",
       "..            ...                   ...             ...  ...       ...   \n",
       "95    4605.399902              184847.0        8.572104  ...       0.0   \n",
       "96   61091.558594              370643.0       19.504339  ...       0.0   \n",
       "97    3646.611572              154271.0        8.979318  ...       0.0   \n",
       "98    2999.765137              149432.0        5.805043  ...       0.0   \n",
       "99  115065.726562              332951.0        4.994162  ...       0.0   \n",
       "\n",
       "    tfidf_91  tfidf_92  tfidf_93  tfidf_94  tfidf_95  tfidf_96  tfidf_97  \\\n",
       "0   0.000000  0.038413  0.000000  0.118715  0.000000  0.108480       0.0   \n",
       "1   0.000000  0.000000  0.000000  0.000000  0.000000  0.112164       0.0   \n",
       "2   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000       0.0   \n",
       "3   0.238013  0.092651  0.000000  0.000000  0.000000  0.000000       0.0   \n",
       "4   0.000000  0.067137  0.086781  0.000000  0.088484  0.000000       0.0   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95  0.000000  0.041894  0.000000  0.000000  0.000000  0.000000       0.0   \n",
       "96  0.000000  0.000000  0.000000  0.143169  0.000000  0.261651       0.0   \n",
       "97  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000       0.0   \n",
       "98  0.000000  0.000000  0.000000  0.120691  0.000000  0.000000       0.0   \n",
       "99  0.071302  0.027756  0.000000  0.085779  0.000000  0.000000       0.0   \n",
       "\n",
       "    tfidf_98  tfidf_99  \n",
       "0   0.000000  0.000000  \n",
       "1   0.000000  0.000000  \n",
       "2   0.000000  0.054876  \n",
       "3   0.000000  0.069394  \n",
       "4   0.000000  0.150855  \n",
       "..       ...       ...  \n",
       "95  0.000000  0.000000  \n",
       "96  0.000000  0.138789  \n",
       "97  0.000000  0.175498  \n",
       "98  0.211061  0.000000  \n",
       "99  0.000000  0.041578  \n",
       "\n",
       "[100 rows x 242 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_cn</th>\n",
       "      <th>silence_count</th>\n",
       "      <th>silence_duration</th>\n",
       "      <th>silence_count__length</th>\n",
       "      <th>silence_duration__length</th>\n",
       "      <th>silence_count__lang</th>\n",
       "      <th>silence_duration__lang</th>\n",
       "      <th>voice_energy</th>\n",
       "      <th>voice_zero_crossings</th>\n",
       "      <th>voice_kurtosis</th>\n",
       "      <th>...</th>\n",
       "      <th>tfidf_90</th>\n",
       "      <th>tfidf_91</th>\n",
       "      <th>tfidf_92</th>\n",
       "      <th>tfidf_93</th>\n",
       "      <th>tfidf_94</th>\n",
       "      <th>tfidf_95</th>\n",
       "      <th>tfidf_96</th>\n",
       "      <th>tfidf_97</th>\n",
       "      <th>tfidf_98</th>\n",
       "      <th>tfidf_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "      <td>39.24</td>\n",
       "      <td>5.192174e-06</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>54</td>\n",
       "      <td>78.48</td>\n",
       "      <td>240.086258</td>\n",
       "      <td>300478.0</td>\n",
       "      <td>10.802467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038413</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>5.56</td>\n",
       "      <td>7.718780e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>8</td>\n",
       "      <td>11.12</td>\n",
       "      <td>25020.804688</td>\n",
       "      <td>283295.0</td>\n",
       "      <td>6.063213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>10.75</td>\n",
       "      <td>8.705226e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>10</td>\n",
       "      <td>21.50</td>\n",
       "      <td>56735.906250</td>\n",
       "      <td>293135.0</td>\n",
       "      <td>7.146604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>20.74</td>\n",
       "      <td>2.192609e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>28</td>\n",
       "      <td>41.48</td>\n",
       "      <td>19778.640625</td>\n",
       "      <td>371382.0</td>\n",
       "      <td>8.957318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.238013</td>\n",
       "      <td>0.092651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "      <td>22.22</td>\n",
       "      <td>2.937279e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>30</td>\n",
       "      <td>44.44</td>\n",
       "      <td>189.070831</td>\n",
       "      <td>258467.0</td>\n",
       "      <td>6.062391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067137</td>\n",
       "      <td>0.086781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>17.93</td>\n",
       "      <td>2.065372e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>11</td>\n",
       "      <td>17.93</td>\n",
       "      <td>4605.399902</td>\n",
       "      <td>184847.0</td>\n",
       "      <td>8.572104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>True</td>\n",
       "      <td>31</td>\n",
       "      <td>41.70</td>\n",
       "      <td>4.289652e-06</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>62</td>\n",
       "      <td>83.40</td>\n",
       "      <td>61091.558594</td>\n",
       "      <td>370643.0</td>\n",
       "      <td>19.504339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>13.16</td>\n",
       "      <td>1.718577e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>18</td>\n",
       "      <td>26.32</td>\n",
       "      <td>3646.611572</td>\n",
       "      <td>154271.0</td>\n",
       "      <td>8.979318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>11.35</td>\n",
       "      <td>1.496372e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>16</td>\n",
       "      <td>22.70</td>\n",
       "      <td>2999.765137</td>\n",
       "      <td>149432.0</td>\n",
       "      <td>5.805043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.211061</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>115065.726562</td>\n",
       "      <td>332951.0</td>\n",
       "      <td>4.994162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071302</td>\n",
       "      <td>0.027756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 242 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4.1.3 Post-Extraction Works\n",
    "\n",
    "After extraction, we filter away unimportant features to keep the feature list clean. The list is based on the feature importance list fetched earlier with CatBoost as a backend. To replicate, remove this cell and do CatBoost training."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T14:00:08.787918Z",
     "start_time": "2024-12-29T14:00:08.758016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(100):\n",
    "    if i not in [87, 94, 96, 58, 12, 86, 56, 75, 54, 11, 47, 1, 13, 2, 10, 63, 17, 15, 0, 50, 99, 70]:\n",
    "        df_feats = df_feats.drop(columns=[f'tfidf_{i}'])\n",
    "\n",
    "df_feats"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    is_cn  silence_count  silence_duration  silence_count__length  \\\n",
       "0    True             27             39.24           5.192174e-06   \n",
       "1    True              4              5.56           7.718780e-07   \n",
       "2    True              5             10.75           8.705226e-07   \n",
       "3    True             14             20.74           2.192609e-06   \n",
       "4    True             15             22.22           2.937279e-06   \n",
       "..    ...            ...               ...                    ...   \n",
       "95  False             11             17.93           2.065372e-06   \n",
       "96   True             31             41.70           4.289652e-06   \n",
       "97   True              9             13.16           1.718577e-06   \n",
       "98   True              8             11.35           1.496372e-06   \n",
       "99   True              0              0.00           0.000000e+00   \n",
       "\n",
       "    silence_duration__length  silence_count__lang  silence_duration__lang  \\\n",
       "0                   0.000008                   54                   78.48   \n",
       "1                   0.000001                    8                   11.12   \n",
       "2                   0.000002                   10                   21.50   \n",
       "3                   0.000003                   28                   41.48   \n",
       "4                   0.000004                   30                   44.44   \n",
       "..                       ...                  ...                     ...   \n",
       "95                  0.000003                   11                   17.93   \n",
       "96                  0.000006                   62                   83.40   \n",
       "97                  0.000003                   18                   26.32   \n",
       "98                  0.000002                   16                   22.70   \n",
       "99                  0.000000                    0                    0.00   \n",
       "\n",
       "     voice_energy  voice_zero_crossings  voice_kurtosis  ...  tfidf_56  \\\n",
       "0      240.086258              300478.0       10.802467  ...  0.000000   \n",
       "1    25020.804688              283295.0        6.063213  ...  0.175000   \n",
       "2    56735.906250              293135.0        7.146604  ...  0.000000   \n",
       "3    19778.640625              371382.0        8.957318  ...  0.000000   \n",
       "4      189.070831              258467.0        6.062391  ...  0.000000   \n",
       "..            ...                   ...             ...  ...       ...   \n",
       "95    4605.399902              184847.0        8.572104  ...  0.000000   \n",
       "96   61091.558594              370643.0       19.504339  ...  0.000000   \n",
       "97    3646.611572              154271.0        8.979318  ...  0.172069   \n",
       "98    2999.765137              149432.0        5.805043  ...  0.344138   \n",
       "99  115065.726562              332951.0        4.994162  ...  0.244591   \n",
       "\n",
       "    tfidf_58  tfidf_63  tfidf_70  tfidf_75  tfidf_86  tfidf_87  tfidf_94  \\\n",
       "0   0.000000  0.000000  0.000000  0.000000  0.092303       0.0  0.118715   \n",
       "1   0.095268  0.127433  0.000000  0.000000  0.000000       0.0  0.000000   \n",
       "2   0.175740  0.117538  0.174000  0.000000  0.000000       0.0  0.000000   \n",
       "3   0.111118  0.148635  0.000000  0.000000  0.000000       0.0  0.000000   \n",
       "4   0.161038  0.000000  0.159443  0.000000  0.080662       0.0  0.000000   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95  0.100488  0.000000  0.198985  0.000000  0.000000       0.0  0.000000   \n",
       "96  0.000000  0.148635  0.000000  0.000000  0.000000       0.0  0.143169   \n",
       "97  0.000000  0.000000  0.000000  0.266139  0.000000       0.0  0.000000   \n",
       "98  0.000000  0.000000  0.000000  0.000000  0.281515       0.0  0.120691   \n",
       "99  0.066576  0.000000  0.000000  0.094577  0.000000       0.0  0.085779   \n",
       "\n",
       "    tfidf_96  tfidf_99  \n",
       "0   0.108480  0.000000  \n",
       "1   0.112164  0.000000  \n",
       "2   0.000000  0.054876  \n",
       "3   0.000000  0.069394  \n",
       "4   0.000000  0.150855  \n",
       "..       ...       ...  \n",
       "95  0.000000  0.000000  \n",
       "96  0.261651  0.138789  \n",
       "97  0.000000  0.175498  \n",
       "98  0.000000  0.000000  \n",
       "99  0.000000  0.041578  \n",
       "\n",
       "[100 rows x 164 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_cn</th>\n",
       "      <th>silence_count</th>\n",
       "      <th>silence_duration</th>\n",
       "      <th>silence_count__length</th>\n",
       "      <th>silence_duration__length</th>\n",
       "      <th>silence_count__lang</th>\n",
       "      <th>silence_duration__lang</th>\n",
       "      <th>voice_energy</th>\n",
       "      <th>voice_zero_crossings</th>\n",
       "      <th>voice_kurtosis</th>\n",
       "      <th>...</th>\n",
       "      <th>tfidf_56</th>\n",
       "      <th>tfidf_58</th>\n",
       "      <th>tfidf_63</th>\n",
       "      <th>tfidf_70</th>\n",
       "      <th>tfidf_75</th>\n",
       "      <th>tfidf_86</th>\n",
       "      <th>tfidf_87</th>\n",
       "      <th>tfidf_94</th>\n",
       "      <th>tfidf_96</th>\n",
       "      <th>tfidf_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "      <td>39.24</td>\n",
       "      <td>5.192174e-06</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>54</td>\n",
       "      <td>78.48</td>\n",
       "      <td>240.086258</td>\n",
       "      <td>300478.0</td>\n",
       "      <td>10.802467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.092303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.118715</td>\n",
       "      <td>0.108480</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>5.56</td>\n",
       "      <td>7.718780e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>8</td>\n",
       "      <td>11.12</td>\n",
       "      <td>25020.804688</td>\n",
       "      <td>283295.0</td>\n",
       "      <td>6.063213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.095268</td>\n",
       "      <td>0.127433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112164</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>10.75</td>\n",
       "      <td>8.705226e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>10</td>\n",
       "      <td>21.50</td>\n",
       "      <td>56735.906250</td>\n",
       "      <td>293135.0</td>\n",
       "      <td>7.146604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175740</td>\n",
       "      <td>0.117538</td>\n",
       "      <td>0.174000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>20.74</td>\n",
       "      <td>2.192609e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>28</td>\n",
       "      <td>41.48</td>\n",
       "      <td>19778.640625</td>\n",
       "      <td>371382.0</td>\n",
       "      <td>8.957318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111118</td>\n",
       "      <td>0.148635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "      <td>22.22</td>\n",
       "      <td>2.937279e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>30</td>\n",
       "      <td>44.44</td>\n",
       "      <td>189.070831</td>\n",
       "      <td>258467.0</td>\n",
       "      <td>6.062391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.161038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159443</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>17.93</td>\n",
       "      <td>2.065372e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>11</td>\n",
       "      <td>17.93</td>\n",
       "      <td>4605.399902</td>\n",
       "      <td>184847.0</td>\n",
       "      <td>8.572104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.198985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>True</td>\n",
       "      <td>31</td>\n",
       "      <td>41.70</td>\n",
       "      <td>4.289652e-06</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>62</td>\n",
       "      <td>83.40</td>\n",
       "      <td>61091.558594</td>\n",
       "      <td>370643.0</td>\n",
       "      <td>19.504339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143169</td>\n",
       "      <td>0.261651</td>\n",
       "      <td>0.138789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>13.16</td>\n",
       "      <td>1.718577e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>18</td>\n",
       "      <td>26.32</td>\n",
       "      <td>3646.611572</td>\n",
       "      <td>154271.0</td>\n",
       "      <td>8.979318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>11.35</td>\n",
       "      <td>1.496372e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>16</td>\n",
       "      <td>22.70</td>\n",
       "      <td>2999.765137</td>\n",
       "      <td>149432.0</td>\n",
       "      <td>5.805043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>115065.726562</td>\n",
       "      <td>332951.0</td>\n",
       "      <td>4.994162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244591</td>\n",
       "      <td>0.066576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 164 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0F5_kI95LuZ2"
   },
   "source": [
    "## 4.2 Model stage\n",
    "\n",
    "Describe the ML model(s) that you will build. Explain why you have chosen them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Ensemble stage\n",
    "\n",
    "Describe any ensemble approach you might have included. Explain why you have chosen them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZQPxztuL9AW"
   },
   "source": [
    "# 5 Dataset\n",
    "\n",
    "Describe the datasets that you will create to build and evaluate your models. Your datasets need to be based on our MLEnd Deception Dataset. After describing the datasets, build them here. You can explore and visualise the datasets here as well. \n",
    "\n",
    "If you are building separate training and validation datasets, do it here. Explain clearly how you are building such datasets, how you are ensuring that they serve their purpose (i.e. they are independent and consist of IID samples) and any limitations you might think of. It is always important to identify any limitations as early as possible. The scope and validity of your conclusions will depend on your ability to understand the limitations of your approach.\n",
    "\n",
    "If you are exploring different datasets, create different subsections for each dataset and give them a name (e.g. 5.1 Dataset A, 5.2 Dataset B, 5.3 Dataset 5.3) .\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qf7GN1aeXJI"
   },
   "source": [
    "# 6 Experiments and results\n",
    "\n",
    "Carry out your experiments here. Analyse and explain your results. Unexplained results are worthless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSrJCR_cekPO"
   },
   "source": [
    "# 7 Conclusions\n",
    "\n",
    "Your conclusions, suggestions for improvements, etc should go here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 References\n",
    "\n",
    "Acknowledge others here (books, papers, repositories, libraries, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
