{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b7b1e15f9acf430",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "cf0a77ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T07:06:22.476456Z",
     "start_time": "2024-12-28T07:06:22.111374Z"
    }
   },
   "source": [
    "import codecs\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "cn_stopwords = set([ line.rstrip() for line in codecs.open('dataset/cn_stop_words.txt',\"r\", encoding=\"utf-8\")])\n",
    "en_stopwords = set([ line.rstrip() for line in codecs.open('dataset/en_stop_words.txt',\"r\", encoding=\"utf-8\")])\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def remove_new_line(text):\n",
    "    text = text.replace('\\n', '')\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "def lemmatize(review):\n",
    "    review = re.sub(r'[^a-zA-Z\\s]', '', review)\n",
    "    review = review.lower()\n",
    "    review = nltk.word_tokenize(review)\n",
    "    corpus = []\n",
    "    for y in review:\n",
    "        if y not in en_stopwords:\n",
    "            corpus.append(lemmatizer.lemmatize(y))\n",
    "    return ' '.join(corpus)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "a10c24d65098a205",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T07:06:24.339907Z",
     "start_time": "2024-12-28T07:06:23.483529Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_attributes = pd.read_csv('dataset/stories_attributes.csv')\n",
    "df_text = pd.read_csv('dataset/stories_in_text.csv')\n",
    "df_translated = pd.read_csv('dataset/stories_translated.csv')\n",
    "\n",
    "df = pd.merge(df_attributes, df_text, on=['filename', 'Language'])\n",
    "df = pd.merge(df, df_translated, on=['filename', 'Language'])\n",
    "\n",
    "# 0 = truth, 1 = deceptive\n",
    "df['label'] = np.where(df['Story_type'] == 'Deceptive Story', 1, 0)\n",
    "df['idx'] = range(len(df))\n",
    "df['text_line'] = df['text'].apply(remove_new_line)\n",
    "df['text_lemma'] = df['text_english'].apply(lemmatize)\n",
    "df = df.drop(columns=['Story_type'])\n",
    "df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     filename Language                                               text  \\\n",
       "0   00001.wav  Chinese  2021年的冬天，\\n我回了一趟老家探望外婆，\\n那年他身体不好，\\n住在离村子不远的小镇医...   \n",
       "1   00002.wav  Chinese  2022年暑假我终于实现了去云南旅行的梦想。\\n云南的美景和独特文化一直是我向往的，\\n而这...   \n",
       "2   00003.wav  Chinese  这是我的故事。\\n我的旅程从据著名的故宫开始，它是世界上最大保存\\n保存最完整的皇宫建筑群。...   \n",
       "3   00004.wav  Chinese  在2020年呢我报名参加了学校组织的美国研学活动，\\n我跟我的另外两个同学以及许多老师同学们...   \n",
       "4   00005.wav  Chinese  今天我想和大家分享我去年的陕西之旅，\\n当我踏上这片古老的土地，心中充满了期待与敬畏。\\n我...   \n",
       "..        ...      ...                                                ...   \n",
       "95  00096.wav  English   Uh. \\nW is a\\n uh my friends and I decided to...   \n",
       "96  00097.wav  Chinese  上周\\n我前往宜家\\n孤儿院\\n去看望我大学时期志愿服务时认识的小男孩，\\n浩浩，\\n那是一...   \n",
       "97  00098.wav  Chinese  呃上个周末我和我的朋友们准备去参加一场徒步旅行，\\n然后目标是一片森林，\\n那天的天气比较阴...   \n",
       "98  00099.wav  Chinese  啊一次有一次吧我和我的几个朋友去参加一个周末的艺术展览，\\n我们都挺喜欢艺术的，所以就提前计...   \n",
       "99  00100.wav  Chinese  2021年我去了一趟农村拜访我很久没见的表哥表哥一家住在偏远的乡下，那里风景优美，4周都是起...   \n",
       "\n",
       "                                         text_english  label  idx  \\\n",
       "0   In the winter of 2021, I went back to my homet...      0    0   \n",
       "1   I finally realized my dream of traveling to Yu...      0    1   \n",
       "2   This is my story. My journey begins with the f...      0    2   \n",
       "3   In 2020, I registered for the school's organiz...      0    3   \n",
       "4   Today, I would like to share with you my trip ...      0    4   \n",
       "..                                                ...    ...  ...   \n",
       "95  Uh. W is a uh my friends and I decided to go h...      0   95   \n",
       "96  Last week, I went to IKEA Orphanage to visit t...      1   96   \n",
       "97  Last weekend, my friends and I were planning t...      0   97   \n",
       "98  Ah, once in a while, my friends and I went to ...      1   98   \n",
       "99  In 2021, I went to the countryside to visit my...      0   99   \n",
       "\n",
       "                                            text_line  \\\n",
       "0   2021年的冬天，我回了一趟老家探望外婆，那年他身体不好，住在离村子不远的小镇医院里，冬天的...   \n",
       "1   2022年暑假我终于实现了去云南旅行的梦想。云南的美景和独特文化一直是我向往的，而这次旅行让...   \n",
       "2   这是我的故事。我的旅程从据著名的故宫开始，它是世界上最大保存保存最完整的皇宫建筑群。当我踏入...   \n",
       "3   在2020年呢我报名参加了学校组织的美国研学活动，我跟我的另外两个同学以及许多老师同学们一起...   \n",
       "4   今天我想和大家分享我去年的陕西之旅，当我踏上这片古老的土地，心中充满了期待与敬畏。我在陕西之...   \n",
       "..                                                ...   \n",
       "95  Uh. W is a uh my friends and I decided to go h...   \n",
       "96  上周我前往宜家孤儿院去看望我大学时期志愿服务时认识的小男孩，浩浩，那是一个安静的冬日午后阳光...   \n",
       "97  呃上个周末我和我的朋友们准备去参加一场徒步旅行，然后目标是一片森林，那天的天气比较阴沉，并且...   \n",
       "98  啊一次有一次吧我和我的几个朋友去参加一个周末的艺术展览，我们都挺喜欢艺术的，所以就提前计划好...   \n",
       "99  2021年我去了一趟农村拜访我很久没见的表哥表哥一家住在偏远的乡下，那里风景优美，4周都是起...   \n",
       "\n",
       "                                           text_lemma  \n",
       "0   winter hometown visit grandmother good health ...  \n",
       "1   finally realized dream traveling yunnan summer...  \n",
       "2   story journey famous forbidden city largest pr...  \n",
       "3   registered school organized study tour united ...  \n",
       "4   today share trip shaanxi year stepped ancient ...  \n",
       "..                                                ...  \n",
       "95  uh uh friend decided hiking life true uh left ...  \n",
       "96  week ikea orphanage visit boy met college volu...  \n",
       "97  weekend friend planning participate hiking tri...  \n",
       "98  friend attend weekend art exhibition love art ...  \n",
       "99  countryside visit cousin family hadnt long tim...  \n",
       "\n",
       "[100 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>Language</th>\n",
       "      <th>text</th>\n",
       "      <th>text_english</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "      <th>text_line</th>\n",
       "      <th>text_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001.wav</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>2021年的冬天，\\n我回了一趟老家探望外婆，\\n那年他身体不好，\\n住在离村子不远的小镇医...</td>\n",
       "      <td>In the winter of 2021, I went back to my homet...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021年的冬天，我回了一趟老家探望外婆，那年他身体不好，住在离村子不远的小镇医院里，冬天的...</td>\n",
       "      <td>winter hometown visit grandmother good health ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002.wav</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>2022年暑假我终于实现了去云南旅行的梦想。\\n云南的美景和独特文化一直是我向往的，\\n而这...</td>\n",
       "      <td>I finally realized my dream of traveling to Yu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2022年暑假我终于实现了去云南旅行的梦想。云南的美景和独特文化一直是我向往的，而这次旅行让...</td>\n",
       "      <td>finally realized dream traveling yunnan summer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00003.wav</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>这是我的故事。\\n我的旅程从据著名的故宫开始，它是世界上最大保存\\n保存最完整的皇宫建筑群。...</td>\n",
       "      <td>This is my story. My journey begins with the f...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>这是我的故事。我的旅程从据著名的故宫开始，它是世界上最大保存保存最完整的皇宫建筑群。当我踏入...</td>\n",
       "      <td>story journey famous forbidden city largest pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00004.wav</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>在2020年呢我报名参加了学校组织的美国研学活动，\\n我跟我的另外两个同学以及许多老师同学们...</td>\n",
       "      <td>In 2020, I registered for the school's organiz...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>在2020年呢我报名参加了学校组织的美国研学活动，我跟我的另外两个同学以及许多老师同学们一起...</td>\n",
       "      <td>registered school organized study tour united ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00005.wav</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>今天我想和大家分享我去年的陕西之旅，\\n当我踏上这片古老的土地，心中充满了期待与敬畏。\\n我...</td>\n",
       "      <td>Today, I would like to share with you my trip ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>今天我想和大家分享我去年的陕西之旅，当我踏上这片古老的土地，心中充满了期待与敬畏。我在陕西之...</td>\n",
       "      <td>today share trip shaanxi year stepped ancient ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>00096.wav</td>\n",
       "      <td>English</td>\n",
       "      <td>Uh. \\nW is a\\n uh my friends and I decided to...</td>\n",
       "      <td>Uh. W is a uh my friends and I decided to go h...</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>Uh. W is a uh my friends and I decided to go h...</td>\n",
       "      <td>uh uh friend decided hiking life true uh left ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>00097.wav</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>上周\\n我前往宜家\\n孤儿院\\n去看望我大学时期志愿服务时认识的小男孩，\\n浩浩，\\n那是一...</td>\n",
       "      <td>Last week, I went to IKEA Orphanage to visit t...</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>上周我前往宜家孤儿院去看望我大学时期志愿服务时认识的小男孩，浩浩，那是一个安静的冬日午后阳光...</td>\n",
       "      <td>week ikea orphanage visit boy met college volu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>00098.wav</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>呃上个周末我和我的朋友们准备去参加一场徒步旅行，\\n然后目标是一片森林，\\n那天的天气比较阴...</td>\n",
       "      <td>Last weekend, my friends and I were planning t...</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>呃上个周末我和我的朋友们准备去参加一场徒步旅行，然后目标是一片森林，那天的天气比较阴沉，并且...</td>\n",
       "      <td>weekend friend planning participate hiking tri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>00099.wav</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>啊一次有一次吧我和我的几个朋友去参加一个周末的艺术展览，\\n我们都挺喜欢艺术的，所以就提前计...</td>\n",
       "      <td>Ah, once in a while, my friends and I went to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>啊一次有一次吧我和我的几个朋友去参加一个周末的艺术展览，我们都挺喜欢艺术的，所以就提前计划好...</td>\n",
       "      <td>friend attend weekend art exhibition love art ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>00100.wav</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>2021年我去了一趟农村拜访我很久没见的表哥表哥一家住在偏远的乡下，那里风景优美，4周都是起...</td>\n",
       "      <td>In 2021, I went to the countryside to visit my...</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>2021年我去了一趟农村拜访我很久没见的表哥表哥一家住在偏远的乡下，那里风景优美，4周都是起...</td>\n",
       "      <td>countryside visit cousin family hadnt long tim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "383302da301da69",
   "metadata": {},
   "source": [
    "### Features from Text"
   ]
  },
  {
   "cell_type": "code",
   "id": "fe376f2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T07:06:25.441483Z",
     "start_time": "2024-12-28T07:06:25.435168Z"
    }
   },
   "source": [
    "def count_modal_particles(text):\n",
    "    particles = [\n",
    "        '啊', '呀', '啦', '吧', '呢', '嘛', '呗', '么', '噢', '呃', '额', '唔', '嗯',\n",
    "        ' uh ', 'uh,', '\\nuh ', 'uh.', ' oh ', 'oh,', '\\noh ', 'oh.', ' um ', 'um,', '\\num ', 'um.', ' ah ', 'ah,', '\\nah ', 'ah.',\n",
    "    ]\n",
    "    count = 0\n",
    "    for particle in particles:\n",
    "        count += len(re.findall(particle, text.lower()))\n",
    "    return count\n",
    "\n",
    "def count_new_line(text):\n",
    "    return len(re.findall('\\n', text))\n",
    "\n",
    "def calculate_repetition(text):\n",
    "    words = [w for w in text.split() if w]\n",
    "    if not words:\n",
    "        return 0\n",
    "        \n",
    "    word_counts = {}\n",
    "    for word in words:\n",
    "        word_counts[word] = word_counts.get(word, 0) + 1\n",
    "    repeated_words = sum(count - 1 for count in word_counts.values())\n",
    "    repetition_ratio = repeated_words / len(words)\n",
    "    \n",
    "    return repetition_ratio\n",
    "\n",
    "def count_stop_words(lang, text):\n",
    "    stopwords = cn_stopwords if lang == 'Chinese' else en_stopwords\n",
    "    count = 0\n",
    "    for word in stopwords:\n",
    "        pattern = r'\\b' + re.escape(word) + r'\\b'\n",
    "        try:\n",
    "            matches = re.findall(pattern, text.lower())\n",
    "            count += len(matches)\n",
    "        except re.error:\n",
    "            continue\n",
    "    return count"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "31905d7b24ebcf22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T07:06:28.322857Z",
     "start_time": "2024-12-28T07:06:26.258197Z"
    }
   },
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Basic Information\n",
    "feats = {\n",
    "    'is_cn': df['Language'] == 'Chinese', \n",
    "    'modal_particles': df['text'].apply(count_modal_particles),\n",
    "    'new_line': df['text'].apply(count_new_line),\n",
    "    'repetition': df['text_line'].apply(calculate_repetition),\n",
    "    'stop_words': [count_stop_words(row['Language'], row['text_line']) \n",
    "                  for _, row in df.iterrows()],\n",
    "    'length_en': df['text_english'].apply(len),\n",
    "    'word_count_lemma': df['text_lemma'].apply(lambda x: x.split()) \\\n",
    "                        .apply(len).apply(lambda x: x+1),\n",
    "    'word_richness': df['text_english'].apply(lambda x: len(set(x)) / len(x)),\n",
    "    'sentence_count': df['text_english'].apply(lambda x: x.count('.') + x.count('!') + x.count('?')),\n",
    "}\n",
    "\n",
    "# TF-IDF Related Features\n",
    "tfidf_en = TfidfVectorizer(\n",
    "    max_features=100,\n",
    "    ngram_range=(1, 3),\n",
    "    stop_words='english'\n",
    ")\n",
    "tfidf_matrix_en = tfidf_en.fit_transform(df['text_lemma'])\n",
    "\n",
    "feats['tfidf_vec_len'] = pd.Series([len(x.indices) for x in tfidf_matrix_en])\n",
    "feats['tfidf_mean'] = pd.Series(np.array(tfidf_matrix_en.mean(axis=1)).flatten())\n",
    "feats['tfidf_std'] =  pd.Series([np.std(x.data) for x in tfidf_matrix_en])\n",
    "\n",
    "for i in range(100):\n",
    "    feats[f'tfidf_{i}'] = pd.Series(tfidf_matrix_en.toarray()[i])\n",
    "\n",
    "df_feats = pd.DataFrame(feats)\n",
    "df_feats"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    is_cn  modal_particles  new_line  repetition  stop_words  length_en  \\\n",
       "0    True                2        44    0.000000          39       1730   \n",
       "1    True                0        29    0.000000          36       1898   \n",
       "2    True                0        33    0.000000          38       2158   \n",
       "3    True                6        43    0.000000          44       2061   \n",
       "4    True                0        33    0.000000          31       1701   \n",
       "..    ...              ...       ...         ...         ...        ...   \n",
       "95  False               19        42    0.373786         142        996   \n",
       "96   True                1        84    0.000000          53       1844   \n",
       "97   True               13        35    0.000000          33       1433   \n",
       "98   True                9        29    0.000000          26       1514   \n",
       "99   True                0        39    0.000000          69       3669   \n",
       "\n",
       "    word_count_lemma  word_richness  sentence_count  tfidf_vec_len  ...  \\\n",
       "0                116       0.023699              19             30  ...   \n",
       "1                153       0.020548              20             28  ...   \n",
       "2                173       0.021779              20             24  ...   \n",
       "3                146       0.025230              26             25  ...   \n",
       "4                139       0.026455              15             16  ...   \n",
       "..               ...            ...             ...            ...  ...   \n",
       "95                70       0.037149              24             16  ...   \n",
       "96               137       0.023861              24             23  ...   \n",
       "97                79       0.028611              15             15  ...   \n",
       "98               103       0.025099              13             17  ...   \n",
       "99               288       0.010902              33             39  ...   \n",
       "\n",
       "    tfidf_90  tfidf_91  tfidf_92  tfidf_93  tfidf_94  tfidf_95  tfidf_96  \\\n",
       "0        0.0  0.000000  0.038413  0.000000  0.118715  0.000000  0.108480   \n",
       "1        0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.112164   \n",
       "2        0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3        0.0  0.238013  0.092651  0.000000  0.000000  0.000000  0.000000   \n",
       "4        0.0  0.000000  0.067137  0.086781  0.000000  0.088484  0.000000   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95       0.0  0.000000  0.041894  0.000000  0.000000  0.000000  0.000000   \n",
       "96       0.0  0.000000  0.000000  0.000000  0.143169  0.000000  0.261651   \n",
       "97       0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "98       0.0  0.000000  0.000000  0.000000  0.120691  0.000000  0.000000   \n",
       "99       0.0  0.071302  0.027756  0.000000  0.085779  0.000000  0.000000   \n",
       "\n",
       "    tfidf_97  tfidf_98  tfidf_99  \n",
       "0        0.0  0.000000  0.000000  \n",
       "1        0.0  0.000000  0.000000  \n",
       "2        0.0  0.000000  0.054876  \n",
       "3        0.0  0.000000  0.069394  \n",
       "4        0.0  0.000000  0.150855  \n",
       "..       ...       ...       ...  \n",
       "95       0.0  0.000000  0.000000  \n",
       "96       0.0  0.000000  0.138789  \n",
       "97       0.0  0.000000  0.175498  \n",
       "98       0.0  0.211061  0.000000  \n",
       "99       0.0  0.000000  0.041578  \n",
       "\n",
       "[100 rows x 112 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_cn</th>\n",
       "      <th>modal_particles</th>\n",
       "      <th>new_line</th>\n",
       "      <th>repetition</th>\n",
       "      <th>stop_words</th>\n",
       "      <th>length_en</th>\n",
       "      <th>word_count_lemma</th>\n",
       "      <th>word_richness</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>tfidf_vec_len</th>\n",
       "      <th>...</th>\n",
       "      <th>tfidf_90</th>\n",
       "      <th>tfidf_91</th>\n",
       "      <th>tfidf_92</th>\n",
       "      <th>tfidf_93</th>\n",
       "      <th>tfidf_94</th>\n",
       "      <th>tfidf_95</th>\n",
       "      <th>tfidf_96</th>\n",
       "      <th>tfidf_97</th>\n",
       "      <th>tfidf_98</th>\n",
       "      <th>tfidf_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39</td>\n",
       "      <td>1730</td>\n",
       "      <td>116</td>\n",
       "      <td>0.023699</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038413</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36</td>\n",
       "      <td>1898</td>\n",
       "      <td>153</td>\n",
       "      <td>0.020548</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38</td>\n",
       "      <td>2158</td>\n",
       "      <td>173</td>\n",
       "      <td>0.021779</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44</td>\n",
       "      <td>2061</td>\n",
       "      <td>146</td>\n",
       "      <td>0.025230</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.238013</td>\n",
       "      <td>0.092651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31</td>\n",
       "      <td>1701</td>\n",
       "      <td>139</td>\n",
       "      <td>0.026455</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067137</td>\n",
       "      <td>0.086781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>42</td>\n",
       "      <td>0.373786</td>\n",
       "      <td>142</td>\n",
       "      <td>996</td>\n",
       "      <td>70</td>\n",
       "      <td>0.037149</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53</td>\n",
       "      <td>1844</td>\n",
       "      <td>137</td>\n",
       "      <td>0.023861</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>35</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33</td>\n",
       "      <td>1433</td>\n",
       "      <td>79</td>\n",
       "      <td>0.028611</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26</td>\n",
       "      <td>1514</td>\n",
       "      <td>103</td>\n",
       "      <td>0.025099</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.211061</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69</td>\n",
       "      <td>3669</td>\n",
       "      <td>288</td>\n",
       "      <td>0.010902</td>\n",
       "      <td>33</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071302</td>\n",
       "      <td>0.027756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 112 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "520cffb895a3c11c",
   "metadata": {},
   "source": [
    "### Features from Audio"
   ]
  },
  {
   "cell_type": "code",
   "id": "dd52de8036c588fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T07:06:40.008172Z",
     "start_time": "2024-12-28T07:06:31.655139Z"
    }
   },
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import torchaudio\n",
    "\n",
    "list_waveform = []\n",
    "list_sample_rate = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    wav_file = f'dataset/stories/{df.iloc[i][\"filename\"]}'\n",
    "    waveform, sample_rate = torchaudio.load(wav_file)\n",
    "    list_waveform.append(waveform)\n",
    "    list_sample_rate.append(sample_rate)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "816841c60b0348afaa2a869239738940"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T07:07:00.148554Z",
     "start_time": "2024-12-28T07:06:55.304379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from feats.audio import get_silence_indices\n",
    "\n",
    "silence_feats = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    # Get Silence Indices\n",
    "    silence_indices = get_silence_indices(list_waveform[i][0].numpy(), list_sample_rate[i])\n",
    "    silence_feats.append([])\n",
    "\n",
    "    # Silence Features\n",
    "    silence_feats[i].append(len(silence_indices))\n",
    "    silence_feats[i].append(sum([end - start for start, end in silence_indices]))\n",
    "\n",
    "    # Silence Features (Length Balanced)\n",
    "    silence_feats[i].append(len(silence_indices) / len(list_waveform[i][0]))\n",
    "    silence_feats[i].append(sum([end - start for start, end in silence_indices]) / len(list_waveform[i][0]))\n",
    "\n",
    "    # Silence Features (Language Balanced)\n",
    "    # Means: If Chinese, do *2, as for students, Chinese is more fluent\n",
    "    silence_feats[i].append(len(silence_indices) * (2 if df.iloc[i]['Language'] == 'Chinese' else 1))\n",
    "    silence_feats[i].append(sum([end - start for start, end in silence_indices]) * (2 if df.iloc[i]['Language'] == 'Chinese' else 1))\n",
    "\n",
    "feats['silence_count'] = [x[0] for x in silence_feats]\n",
    "feats['silence_duration'] = [x[1] for x in silence_feats]\n",
    "feats['silence_count__length'] = [x[2] for x in silence_feats]\n",
    "feats['silence_duration__length'] = [x[3] for x in silence_feats]\n",
    "feats['silence_count__lang'] = [x[4] for x in silence_feats]\n",
    "feats['silence_duration__lang'] = [x[5] for x in silence_feats]"
   ],
   "id": "c473c1c52ec9b00d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "81e80b390b874f9087389f8b67526f53"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T07:07:01.989905Z",
     "start_time": "2024-12-28T07:07:00.822525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "more_audio_feats = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    wf_np = list_waveform[i][0].numpy()\n",
    "    energy = np.sum(np.square(wf_np))\n",
    "    zero_crossings = np.sum(np.diff(np.signbit(wf_np)))\n",
    "    more_audio_feats.append([energy, zero_crossings])\n",
    "more_audio_feats = np.array(more_audio_feats)\n",
    "\n",
    "feats['voice_energy'] = more_audio_feats[:,0]\n",
    "feats['voice_zero_crossings'] = more_audio_feats[:,1]"
   ],
   "id": "1b9d0c1e2a0cdf84",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e6c712a5f38c4dcd8b16ab234c5ab134"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "38a522b2d482ef1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T07:07:08.762367Z",
     "start_time": "2024-12-28T07:07:02.590281Z"
    }
   },
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from feats.audio import get_f_bank_feats\n",
    "\n",
    "f_audio_feats = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    # Get F_Banks Results\n",
    "    f_banks = np.asarray(get_f_bank_feats(list_waveform[i][0], list_sample_rate[i]))\n",
    "    # f_banks = librosa.feature.melspectrogram(y=np.asarray(list_waveform[i][0]), sr=list_sample_rate[i], n_mels=40).T\n",
    "\n",
    "    # Calculate F_Banks Statistics\n",
    "    f_means = np.mean(f_banks, axis=0)  # (40,)\n",
    "    f_all_max = np.max(f_banks, axis=0)  # (40,)\n",
    "    f_all_min = np.min(f_banks, axis=0)  # (40,)\n",
    "    f_stats = np.concatenate([\n",
    "        f_means, f_all_max, f_all_min\n",
    "    ])\n",
    "    f_audio_feats.append(f_stats)\n",
    "\n",
    "f_audio_feats = np.array(f_audio_feats)\n",
    "feat_names = []\n",
    "for stat in ['mean', 'max', 'min']:\n",
    "    for i in range(40):\n",
    "        feat_names.append(f'f_bank_{stat}_{i}')\n",
    "\n",
    "for i, name in enumerate(feat_names):\n",
    "    feats[name] = f_audio_feats[:, i]\n",
    "\n",
    "df_feats = pd.DataFrame(feats)\n",
    "df_feats"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "16d32f920216413ca40518d2ed7276b2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "    is_cn  modal_particles  new_line  repetition  stop_words  length_en  \\\n",
       "0    True                2        44    0.000000          39       1730   \n",
       "1    True                0        29    0.000000          36       1898   \n",
       "2    True                0        33    0.000000          38       2158   \n",
       "3    True                6        43    0.000000          44       2061   \n",
       "4    True                0        33    0.000000          31       1701   \n",
       "..    ...              ...       ...         ...         ...        ...   \n",
       "95  False               19        42    0.373786         142        996   \n",
       "96   True                1        84    0.000000          53       1844   \n",
       "97   True               13        35    0.000000          33       1433   \n",
       "98   True                9        29    0.000000          26       1514   \n",
       "99   True                0        39    0.000000          69       3669   \n",
       "\n",
       "    word_count_lemma  word_richness  sentence_count  tfidf_vec_len  ...  \\\n",
       "0                116       0.023699              19             30  ...   \n",
       "1                153       0.020548              20             28  ...   \n",
       "2                173       0.021779              20             24  ...   \n",
       "3                146       0.025230              26             25  ...   \n",
       "4                139       0.026455              15             16  ...   \n",
       "..               ...            ...             ...            ...  ...   \n",
       "95                70       0.037149              24             16  ...   \n",
       "96               137       0.023861              24             23  ...   \n",
       "97                79       0.028611              15             15  ...   \n",
       "98               103       0.025099              13             17  ...   \n",
       "99               288       0.010902              33             39  ...   \n",
       "\n",
       "    f_bank_min_30  f_bank_min_31  f_bank_min_32  f_bank_min_33  f_bank_min_34  \\\n",
       "0      -12.651694     -12.503399     -12.590755     -11.775176     -11.508147   \n",
       "1      -13.569064     -12.389540     -11.697145     -11.324645     -11.532026   \n",
       "2      -15.622457     -15.197051     -15.086365     -14.994941     -14.642530   \n",
       "3      -15.036171     -15.391803     -15.108377     -14.685904     -14.608970   \n",
       "4      -12.155800     -12.282447     -11.745874     -11.336093     -11.355878   \n",
       "..            ...            ...            ...            ...            ...   \n",
       "95     -15.389595     -15.429474     -15.200507     -14.604245     -14.403071   \n",
       "96     -15.648572     -15.457879     -15.118999     -14.789861     -14.596526   \n",
       "97     -15.673203     -15.451294     -14.987769     -14.702625     -14.606583   \n",
       "98     -15.446148     -15.240155     -15.006281     -14.849434     -14.776314   \n",
       "99     -17.917732     -17.735743     -17.652746     -17.269127     -16.943993   \n",
       "\n",
       "    f_bank_min_35  f_bank_min_36  f_bank_min_37  f_bank_min_38  f_bank_min_39  \n",
       "0      -11.246720     -10.893195     -10.535343     -10.292615     -10.631175  \n",
       "1      -11.258627     -12.141105     -14.172897     -14.942272     -15.357892  \n",
       "2      -14.364624     -13.973715     -14.193736     -13.854203     -13.514560  \n",
       "3      -14.444119     -14.246261     -13.865327     -13.662978     -13.567836  \n",
       "4      -10.746713     -10.516589     -10.324493     -10.271720     -10.323216  \n",
       "..            ...            ...            ...            ...            ...  \n",
       "95     -14.429158     -13.865187     -13.907432     -14.386015     -14.591955  \n",
       "96     -14.431129     -14.217156     -14.117102     -14.373189     -14.782300  \n",
       "97     -14.037570     -13.957192     -13.999018     -14.339170     -14.603734  \n",
       "98     -14.143353     -13.926983     -13.881326     -14.300455     -14.641323  \n",
       "99     -16.708250     -16.531713     -16.525991     -16.550686     -16.851931  \n",
       "\n",
       "[100 rows x 240 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_cn</th>\n",
       "      <th>modal_particles</th>\n",
       "      <th>new_line</th>\n",
       "      <th>repetition</th>\n",
       "      <th>stop_words</th>\n",
       "      <th>length_en</th>\n",
       "      <th>word_count_lemma</th>\n",
       "      <th>word_richness</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>tfidf_vec_len</th>\n",
       "      <th>...</th>\n",
       "      <th>f_bank_min_30</th>\n",
       "      <th>f_bank_min_31</th>\n",
       "      <th>f_bank_min_32</th>\n",
       "      <th>f_bank_min_33</th>\n",
       "      <th>f_bank_min_34</th>\n",
       "      <th>f_bank_min_35</th>\n",
       "      <th>f_bank_min_36</th>\n",
       "      <th>f_bank_min_37</th>\n",
       "      <th>f_bank_min_38</th>\n",
       "      <th>f_bank_min_39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39</td>\n",
       "      <td>1730</td>\n",
       "      <td>116</td>\n",
       "      <td>0.023699</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.651694</td>\n",
       "      <td>-12.503399</td>\n",
       "      <td>-12.590755</td>\n",
       "      <td>-11.775176</td>\n",
       "      <td>-11.508147</td>\n",
       "      <td>-11.246720</td>\n",
       "      <td>-10.893195</td>\n",
       "      <td>-10.535343</td>\n",
       "      <td>-10.292615</td>\n",
       "      <td>-10.631175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36</td>\n",
       "      <td>1898</td>\n",
       "      <td>153</td>\n",
       "      <td>0.020548</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.569064</td>\n",
       "      <td>-12.389540</td>\n",
       "      <td>-11.697145</td>\n",
       "      <td>-11.324645</td>\n",
       "      <td>-11.532026</td>\n",
       "      <td>-11.258627</td>\n",
       "      <td>-12.141105</td>\n",
       "      <td>-14.172897</td>\n",
       "      <td>-14.942272</td>\n",
       "      <td>-15.357892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38</td>\n",
       "      <td>2158</td>\n",
       "      <td>173</td>\n",
       "      <td>0.021779</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.622457</td>\n",
       "      <td>-15.197051</td>\n",
       "      <td>-15.086365</td>\n",
       "      <td>-14.994941</td>\n",
       "      <td>-14.642530</td>\n",
       "      <td>-14.364624</td>\n",
       "      <td>-13.973715</td>\n",
       "      <td>-14.193736</td>\n",
       "      <td>-13.854203</td>\n",
       "      <td>-13.514560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44</td>\n",
       "      <td>2061</td>\n",
       "      <td>146</td>\n",
       "      <td>0.025230</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.036171</td>\n",
       "      <td>-15.391803</td>\n",
       "      <td>-15.108377</td>\n",
       "      <td>-14.685904</td>\n",
       "      <td>-14.608970</td>\n",
       "      <td>-14.444119</td>\n",
       "      <td>-14.246261</td>\n",
       "      <td>-13.865327</td>\n",
       "      <td>-13.662978</td>\n",
       "      <td>-13.567836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31</td>\n",
       "      <td>1701</td>\n",
       "      <td>139</td>\n",
       "      <td>0.026455</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.155800</td>\n",
       "      <td>-12.282447</td>\n",
       "      <td>-11.745874</td>\n",
       "      <td>-11.336093</td>\n",
       "      <td>-11.355878</td>\n",
       "      <td>-10.746713</td>\n",
       "      <td>-10.516589</td>\n",
       "      <td>-10.324493</td>\n",
       "      <td>-10.271720</td>\n",
       "      <td>-10.323216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>42</td>\n",
       "      <td>0.373786</td>\n",
       "      <td>142</td>\n",
       "      <td>996</td>\n",
       "      <td>70</td>\n",
       "      <td>0.037149</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.389595</td>\n",
       "      <td>-15.429474</td>\n",
       "      <td>-15.200507</td>\n",
       "      <td>-14.604245</td>\n",
       "      <td>-14.403071</td>\n",
       "      <td>-14.429158</td>\n",
       "      <td>-13.865187</td>\n",
       "      <td>-13.907432</td>\n",
       "      <td>-14.386015</td>\n",
       "      <td>-14.591955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53</td>\n",
       "      <td>1844</td>\n",
       "      <td>137</td>\n",
       "      <td>0.023861</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.648572</td>\n",
       "      <td>-15.457879</td>\n",
       "      <td>-15.118999</td>\n",
       "      <td>-14.789861</td>\n",
       "      <td>-14.596526</td>\n",
       "      <td>-14.431129</td>\n",
       "      <td>-14.217156</td>\n",
       "      <td>-14.117102</td>\n",
       "      <td>-14.373189</td>\n",
       "      <td>-14.782300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>35</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33</td>\n",
       "      <td>1433</td>\n",
       "      <td>79</td>\n",
       "      <td>0.028611</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.673203</td>\n",
       "      <td>-15.451294</td>\n",
       "      <td>-14.987769</td>\n",
       "      <td>-14.702625</td>\n",
       "      <td>-14.606583</td>\n",
       "      <td>-14.037570</td>\n",
       "      <td>-13.957192</td>\n",
       "      <td>-13.999018</td>\n",
       "      <td>-14.339170</td>\n",
       "      <td>-14.603734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26</td>\n",
       "      <td>1514</td>\n",
       "      <td>103</td>\n",
       "      <td>0.025099</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.446148</td>\n",
       "      <td>-15.240155</td>\n",
       "      <td>-15.006281</td>\n",
       "      <td>-14.849434</td>\n",
       "      <td>-14.776314</td>\n",
       "      <td>-14.143353</td>\n",
       "      <td>-13.926983</td>\n",
       "      <td>-13.881326</td>\n",
       "      <td>-14.300455</td>\n",
       "      <td>-14.641323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69</td>\n",
       "      <td>3669</td>\n",
       "      <td>288</td>\n",
       "      <td>0.010902</td>\n",
       "      <td>33</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.917732</td>\n",
       "      <td>-17.735743</td>\n",
       "      <td>-17.652746</td>\n",
       "      <td>-17.269127</td>\n",
       "      <td>-16.943993</td>\n",
       "      <td>-16.708250</td>\n",
       "      <td>-16.531713</td>\n",
       "      <td>-16.525991</td>\n",
       "      <td>-16.550686</td>\n",
       "      <td>-16.851931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 240 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "2da697ed6f70aeae",
   "metadata": {},
   "source": [
    "### Do Boosting"
   ]
  },
  {
   "cell_type": "code",
   "id": "73d1a8ff053b475b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T08:03:51.652030Z",
     "start_time": "2024-12-28T08:03:38.674057Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import classification_report, roc_curve, auc\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "def fit(use_stacking, use_xgboost, use_lightgbm, use_catboost, use_naivebayes, use_knn_model, n_jobs=8):\n",
    "    X = df_feats\n",
    "    y = df['label']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.21, random_state=42, stratify=y, shuffle=True,\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    base_models = []\n",
    "    if use_xgboost:\n",
    "        base_models.append(('xgboost', XGBClassifier(\n",
    "            random_state=0,\n",
    "            n_jobs=n_jobs,\n",
    "            eval_metric='mlogloss'\n",
    "        )))\n",
    "    if use_lightgbm:\n",
    "        base_models.append(('lightgbm', LGBMClassifier(\n",
    "            random_state=0,\n",
    "            n_jobs=n_jobs,\n",
    "            verbose=-1\n",
    "        )))\n",
    "    if use_catboost:\n",
    "        base_models.append(('catboost', CatBoostClassifier(\n",
    "            random_state=0,\n",
    "            thread_count=n_jobs,\n",
    "            verbose=False\n",
    "        )))\n",
    "    if use_naivebayes:\n",
    "        base_models.append(('naivebayes', GaussianNB()))\n",
    "    if use_knn_model:\n",
    "        base_models.append(('knn_model', KNeighborsClassifier(\n",
    "            n_neighbors=7, # 7 better than 3, 5, 9 and 11\n",
    "            n_jobs=n_jobs,\n",
    "        )))\n",
    "\n",
    "    if use_stacking and len(base_models) > 1:\n",
    "        print(f\"Stacking [{', '.join([name for name, _ in base_models])}]\")\n",
    "        stacking_clf = StackingClassifier(\n",
    "            estimators=base_models,\n",
    "            final_estimator=LogisticRegression(random_state=0, n_jobs=n_jobs,),\n",
    "            passthrough=False,\n",
    "            cv=5,\n",
    "            n_jobs=n_jobs,\n",
    "        )\n",
    "        clf = OneVsRestClassifier(stacking_clf, n_jobs=n_jobs,)\n",
    "    else:\n",
    "        print(f\"Using {base_models[0][0]}\")\n",
    "        clf = OneVsRestClassifier(base_models[0][1], n_jobs=n_jobs,)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    y_pred_proba = clf.predict_proba(X_test)[:,1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(\"ROC AUC:\", f'{roc_auc:.2f}')\n",
    "\n",
    "    return clf\n",
    "\n",
    "use_stacking = True\n",
    "clf = fit(\n",
    "    use_stacking=use_stacking,\n",
    "    use_xgboost=False, use_lightgbm=False, use_catboost=True,\n",
    "    use_naivebayes=True, use_knn_model=True,\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking [catboost, naivebayes, knn_model]\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.55      0.63        11\n",
      "           1       0.62      0.80      0.70        10\n",
      "\n",
      "    accuracy                           0.67        21\n",
      "   macro avg       0.68      0.67      0.66        21\n",
      "weighted avg       0.69      0.67      0.66        21\n",
      "\n",
      "ROC AUC: 0.60\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "id": "d5d0f5086324e7f5",
   "metadata": {},
   "source": [
    "### Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "id": "86d5a01d5b12129f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T07:53:27.871413Z",
     "start_time": "2024-12-28T07:53:27.862968Z"
    }
   },
   "source": [
    "if not use_stacking:\n",
    "    feature_importance = clf.estimators_[0].feature_importances_\n",
    "    feature_names = df_feats.columns\n",
    "\n",
    "    df_importance = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': feature_importance\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "\n",
    "    print(df_importance.to_string(index=False))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Feature  Importance\n",
      "           f_bank_max_19    3.469610\n",
      "                tfidf_87    2.611241\n",
      "                tfidf_94    2.211182\n",
      "           f_bank_min_38    1.886957\n",
      "                tfidf_96    1.818164\n",
      "        word_count_lemma    1.705545\n",
      "           f_bank_min_37    1.638103\n",
      "               tfidf_std    1.584387\n",
      "           f_bank_max_29    1.427630\n",
      "                tfidf_58    1.364338\n",
      "               length_en    1.107262\n",
      "                tfidf_12    1.088263\n",
      "          sentence_count    1.071550\n",
      "           f_bank_max_28    1.020659\n",
      "            f_bank_min_4    0.950734\n",
      "   silence_count__length    0.939993\n",
      "            f_bank_min_9    0.916703\n",
      "        silence_duration    0.859321\n",
      "          f_bank_mean_25    0.832835\n",
      "                tfidf_86    0.829309\n",
      "  silence_duration__lang    0.789480\n",
      "           f_bank_max_23    0.780329\n",
      "                tfidf_56    0.754150\n",
      "           f_bank_max_20    0.747024\n",
      "          f_bank_mean_27    0.731565\n",
      "     silence_count__lang    0.700078\n",
      "                tfidf_75    0.691688\n",
      "silence_duration__length    0.670962\n",
      "           word_richness    0.662191\n",
      "                  energy    0.660614\n",
      "                tfidf_54    0.654861\n",
      "           f_bank_max_30    0.649993\n",
      "          f_bank_mean_29    0.626215\n",
      "          zero_crossings    0.626074\n",
      "                tfidf_11    0.619458\n",
      "                tfidf_47    0.606845\n",
      "           f_bank_min_31    0.604619\n",
      "          f_bank_mean_26    0.600428\n",
      "          f_bank_mean_37    0.581363\n",
      "                 tfidf_1    0.579686\n",
      "           f_bank_max_27    0.575673\n",
      "           tfidf_vec_len    0.571481\n",
      "            f_bank_max_2    0.571032\n",
      "            f_bank_max_3    0.557528\n",
      "                tfidf_13    0.553501\n",
      "           silence_count    0.550868\n",
      "          f_bank_mean_39    0.549611\n",
      "           f_bank_min_17    0.546831\n",
      "            f_bank_max_1    0.542512\n",
      "           f_bank_max_33    0.542085\n",
      "            f_bank_max_7    0.537553\n",
      "                 tfidf_2    0.532967\n",
      "                tfidf_10    0.515379\n",
      "           f_bank_max_22    0.506232\n",
      "           f_bank_min_39    0.495950\n",
      "          f_bank_mean_30    0.495704\n",
      "                tfidf_63    0.487065\n",
      "           f_bank_max_37    0.486179\n",
      "           f_bank_max_16    0.484706\n",
      "          f_bank_mean_14    0.478203\n",
      "           f_bank_max_31    0.475230\n",
      "           f_bank_min_23    0.472755\n",
      "           f_bank_max_25    0.471247\n",
      "                tfidf_17    0.470293\n",
      "           f_bank_max_26    0.462297\n",
      "                tfidf_15    0.460293\n",
      "          f_bank_mean_18    0.458605\n",
      "           f_bank_max_24    0.454820\n",
      "           f_bank_min_16    0.450631\n",
      "           f_bank_min_12    0.445985\n",
      "           f_bank_max_35    0.444336\n",
      "           f_bank_max_34    0.444116\n",
      "            f_bank_max_4    0.441756\n",
      "           f_bank_max_15    0.433986\n",
      "           f_bank_min_10    0.426066\n",
      "            f_bank_max_6    0.425088\n",
      "           f_bank_mean_7    0.424744\n",
      "           f_bank_min_11    0.423804\n",
      "           f_bank_mean_3    0.412797\n",
      "           f_bank_min_26    0.405897\n",
      "           f_bank_min_33    0.405610\n",
      "                 tfidf_0    0.402804\n",
      "           f_bank_min_32    0.402354\n",
      "           f_bank_min_14    0.398920\n",
      "              repetition    0.398810\n",
      "          f_bank_mean_24    0.398172\n",
      "           f_bank_max_17    0.389725\n",
      "                tfidf_50    0.389294\n",
      "           f_bank_min_36    0.388945\n",
      "          f_bank_mean_36    0.387574\n",
      "                tfidf_99    0.374402\n",
      "           f_bank_max_38    0.373607\n",
      "         modal_particles    0.372712\n",
      "            f_bank_min_7    0.372393\n",
      "          f_bank_mean_10    0.372146\n",
      "                tfidf_70    0.371612\n",
      "          f_bank_mean_32    0.367395\n",
      "           f_bank_max_13    0.365478\n",
      "                tfidf_18    0.365004\n",
      "          f_bank_mean_35    0.364278\n",
      "                tfidf_84    0.363397\n",
      "           f_bank_min_30    0.362791\n",
      "            f_bank_min_1    0.362758\n",
      "           f_bank_mean_1    0.360537\n",
      "           f_bank_max_21    0.359229\n",
      "           f_bank_min_13    0.358388\n",
      "           f_bank_min_27    0.356839\n",
      "          f_bank_mean_31    0.353902\n",
      "           f_bank_max_39    0.352136\n",
      "           f_bank_min_18    0.349268\n",
      "          f_bank_mean_13    0.347650\n",
      "              tfidf_mean    0.345105\n",
      "          f_bank_mean_33    0.344332\n",
      "                tfidf_85    0.343504\n",
      "            f_bank_min_6    0.342404\n",
      "                tfidf_77    0.339809\n",
      "                tfidf_91    0.334942\n",
      "           f_bank_min_15    0.334567\n",
      "           f_bank_mean_2    0.331779\n",
      "          f_bank_mean_17    0.331750\n",
      "           f_bank_max_11    0.330183\n",
      "            f_bank_max_0    0.329295\n",
      "          f_bank_mean_28    0.328374\n",
      "           f_bank_min_29    0.324006\n",
      "                tfidf_61    0.323226\n",
      "          f_bank_mean_16    0.319638\n",
      "                tfidf_57    0.313819\n",
      "           f_bank_min_20    0.313430\n",
      "                tfidf_37    0.310941\n",
      "           f_bank_mean_4    0.309525\n",
      "                tfidf_80    0.307274\n",
      "                tfidf_81    0.306905\n",
      "                tfidf_62    0.305934\n",
      "                tfidf_64    0.305356\n",
      "                tfidf_29    0.301950\n",
      "           f_bank_max_14    0.299561\n",
      "            f_bank_min_2    0.296345\n",
      "           f_bank_max_32    0.294131\n",
      "           f_bank_mean_5    0.294055\n",
      "                tfidf_30    0.293351\n",
      "                tfidf_26    0.285579\n",
      "          f_bank_mean_38    0.284558\n",
      "           f_bank_min_25    0.283875\n",
      "            f_bank_max_8    0.279860\n",
      "           f_bank_min_22    0.279087\n",
      "           f_bank_min_34    0.277668\n",
      "                tfidf_90    0.276536\n",
      "          f_bank_mean_22    0.267232\n",
      "                tfidf_51    0.262712\n",
      "              stop_words    0.262677\n",
      "            f_bank_min_8    0.262263\n",
      "           f_bank_min_35    0.260922\n",
      "                tfidf_27    0.259296\n",
      "          f_bank_mean_15    0.259290\n",
      "           f_bank_mean_8    0.252065\n",
      "           f_bank_min_28    0.248560\n",
      "                tfidf_59    0.240995\n",
      "                tfidf_44    0.239616\n",
      "                 tfidf_3    0.239582\n",
      "            f_bank_max_5    0.237741\n",
      "                 tfidf_7    0.232161\n",
      "                tfidf_42    0.231260\n",
      "          f_bank_mean_11    0.227637\n",
      "          f_bank_mean_34    0.227380\n",
      "           f_bank_max_10    0.227329\n",
      "            f_bank_min_3    0.225844\n",
      "                tfidf_45    0.225450\n",
      "                tfidf_74    0.223948\n",
      "                tfidf_92    0.223347\n",
      "                tfidf_72    0.221181\n",
      "                tfidf_73    0.218489\n",
      "                tfidf_28    0.218057\n",
      "                tfidf_14    0.217284\n",
      "          f_bank_mean_19    0.216679\n",
      "            f_bank_min_5    0.215577\n",
      "           f_bank_max_18    0.208687\n",
      "                tfidf_36    0.206593\n",
      "                tfidf_32    0.204616\n",
      "           f_bank_max_12    0.203832\n",
      "                   is_cn    0.202603\n",
      "                tfidf_83    0.201506\n",
      "          f_bank_mean_21    0.201452\n",
      "          f_bank_mean_12    0.199762\n",
      "           f_bank_min_24    0.198419\n",
      "           f_bank_min_19    0.195388\n",
      "           f_bank_max_36    0.194398\n",
      "                tfidf_38    0.193807\n",
      "           f_bank_mean_9    0.193693\n",
      "           f_bank_mean_0    0.191575\n",
      "                tfidf_21    0.190860\n",
      "                tfidf_66    0.190290\n",
      "                tfidf_35    0.184031\n",
      "                tfidf_53    0.183861\n",
      "                tfidf_19    0.183033\n",
      "                 tfidf_6    0.182841\n",
      "                tfidf_68    0.178246\n",
      "                tfidf_65    0.178209\n",
      "           f_bank_mean_6    0.176519\n",
      "                tfidf_31    0.173611\n",
      "          f_bank_mean_23    0.167210\n",
      "           f_bank_min_21    0.166878\n",
      "                 tfidf_9    0.165529\n",
      "                tfidf_71    0.164577\n",
      "                tfidf_43    0.160824\n",
      "            f_bank_max_9    0.159910\n",
      "                tfidf_39    0.157868\n",
      "          f_bank_mean_20    0.153749\n",
      "                tfidf_41    0.151624\n",
      "                tfidf_34    0.150855\n",
      "                 tfidf_8    0.144715\n",
      "                 tfidf_5    0.140624\n",
      "                tfidf_60    0.132623\n",
      "                tfidf_55    0.131783\n",
      "                tfidf_20    0.131228\n",
      "                new_line    0.126958\n",
      "                tfidf_25    0.125708\n",
      "                tfidf_48    0.117540\n",
      "                tfidf_78    0.116596\n",
      "                tfidf_49    0.097883\n",
      "                tfidf_88    0.073177\n",
      "                tfidf_82    0.072964\n",
      "                tfidf_46    0.071059\n",
      "                tfidf_22    0.069195\n",
      "                tfidf_16    0.067151\n",
      "                tfidf_76    0.066987\n",
      "                 tfidf_4    0.064247\n",
      "                tfidf_23    0.061259\n",
      "                tfidf_33    0.061149\n",
      "                tfidf_24    0.050557\n",
      "                tfidf_79    0.044292\n",
      "                tfidf_69    0.041192\n",
      "                tfidf_95    0.041035\n",
      "                tfidf_67    0.032970\n",
      "                tfidf_52    0.032953\n",
      "                tfidf_89    0.025905\n",
      "                tfidf_98    0.010151\n",
      "                tfidf_40    0.009289\n",
      "                tfidf_97    0.006856\n",
      "                tfidf_93    0.002527\n",
      "            f_bank_min_0    0.000000\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "71b97128d6e61a0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T08:04:00.428998Z",
     "start_time": "2024-12-28T08:04:00.319019Z"
    }
   },
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Truth', 'Deceptive'],\n",
    "            yticklabels=['Truth', 'Deceptive'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8f6ef3bc0591f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T17:45:31.666614Z",
     "start_time": "2024-12-25T17:45:31.664514Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
